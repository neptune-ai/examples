{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYNlatILeluO"
   },
   "source": [
    "![Neptune + MosaicML Composer](https://neptune.ai/wp-content/uploads/2023/09/mosiacml.svg)\n",
    "\n",
    "# Neptune + MosaicML Composer\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/mosaicml-composer/notebooks/Neptune_MosaicML_Composer.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/mosaicml-composer/notebooks/Neptune_MosaicML_Composer.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://app.neptune.ai/o/showcase/org/mosaicml-composer/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=Composer-run-overview-9b1f1fae-f543-41d1-a778-8604c9b6503d&shortId=MMLCOMP-6\">\n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/mosaicml-composer/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY6B8JTKeluQ"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "[MosaicML Composer](https://github.com/mosaicml/composer) is a PyTorch library for efficient neural network training.\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Create a Neptune logger for MosaicML Composer\n",
    "* Automatically log your Composer training metadata to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiPydbIreluR"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTVvWzR-eluS"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkNDnnv1PsFg",
    "outputId": "8aaec197-b74a-42e5-f435-0559de9af9d3"
   },
   "outputs": [],
   "source": [
    "! pip install -U -qqq neptune mosaicml torch torchvision \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81QrDUjyPsFh"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJVFqUM9PsFh"
   },
   "outputs": [],
   "source": [
    "import composer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from composer.algorithms import LabelSmoothing, ProgressiveResizing\n",
    "from composer.callbacks import *\n",
    "from composer.loggers import NeptuneLogger\n",
    "from composer.models import ComposerClassifier\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcpySPa-PsFh"
   },
   "source": [
    "## Prepare dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxDdtzdLPsFh",
    "outputId": "bd7eccaf-2a8b-4612-9c53-b35e26319b42"
   },
   "outputs": [],
   "source": [
    "data_directory = \"./data\"\n",
    "batch_size = 512\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_directory, train=True, download=True, transform=transforms)\n",
    "test_dataset = datasets.MNIST(data_directory, train=False, download=True, transform=transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp7oW2rTZEmJ"
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-_l-YLvZEmK"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"Toy convolutional neural network architecture in pytorch for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3, 3), padding=0)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 16, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.adaptive_avg_pool2d(out, (4, 4))\n",
    "        out = torch.flatten(out, 1, -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        return self.fc2(out)\n",
    "\n",
    "\n",
    "model = ComposerClassifier(module=Model(num_classes=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rE_0H9fZEmK"
   },
   "source": [
    "## Configure Composer algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-MPP__QZEmK"
   },
   "outputs": [],
   "source": [
    "label_smoothing = LabelSmoothing(\n",
    "    0.1\n",
    ")  # We're creating an instance of the LabelSmoothing algorithm class\n",
    "\n",
    "prog_resize = ProgressiveResizing(\n",
    "    initial_scale=0.6,  # Size of images at the beginning of training = .6 * default image size\n",
    "    finetune_fraction=0.34,  # Train on default size images for 0.34 of total training time.\n",
    ")\n",
    "\n",
    "algorithms = [label_smoothing, prog_resize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuHu55s1-sMI"
   },
   "source": [
    "## Initialize Composer callbacks (optional)\n",
    "Neptune works out-of-the-box with all Composer callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8lg9l1JcwPa"
   },
   "outputs": [],
   "source": [
    "checkpointsaver = CheckpointSaver(remote_file_name=\"checkpoints/ep{epoch}-ba{batch}-rank{rank}.pt\")\n",
    "speedmonitor = SpeedMonitor()\n",
    "runtimeestimator = RuntimeEstimator()\n",
    "lrmonitor = LRMonitor()\n",
    "optimizermonitor = OptimizerMonitor()\n",
    "memorymonitor = MemoryMonitor()\n",
    "memorysnapshot = MemorySnapshot(remote_file_name=\"memory_traces/snapshot/{rank}\")\n",
    "oomobserver = OOMObserver(remote_file_name=\"memory_traces/oom/{rank}\")\n",
    "imagevisualiser = ImageVisualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvBNFkT0PsFh"
   },
   "source": [
    "## Create `neptune_logger`\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/mosaicml-composer](https://app.neptune.ai/o/common/org/mosaicml-composer). **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    tags=[\"mnist\", \"notebook\"],  # (optional) use your own\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. To copy the project path, open the settings menu and select **Details & privacy**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z056VXq1PsFh"
   },
   "outputs": [],
   "source": [
    "from neptune import ANONYMOUS_API_TOKEN\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_token=ANONYMOUS_API_TOKEN,  # or replace with your own\n",
    "    project=\"common/mosaicml-composer\",  # or replace with your own\n",
    "    tags=[\"mnist\", \"notebook\"],  # (optional) use your own\n",
    "    upload_checkpoints=True,\n",
    "    capture_stdout=True,\n",
    "    capture_stderr=True,\n",
    "    capture_traceback=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4XBrMZIPsFi"
   },
   "source": [
    "## Train model with Neptune logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659,
     "referenced_widgets": [
      "a60742a0296f43c38a2aae358d9a47af",
      "c252924f2e5f46a6b2d04cbb0d11f71d",
      "1e37d48afb614abaab1cf7636e6c8386",
      "33756aff8c824053b2b743ecd066752b",
      "acded268cbae4f59a0b56eee401b6c69",
      "21704bb8379d4260bae48537a5327e9a",
      "d71cd3f8d235451a9b05f8d44a5e0af0",
      "2e7c25962a134cb99b18c0ab680197cd",
      "5214f2708f474ab7a990d9aaa16db9c5",
      "71c07b5e5b0b46488b25b2a0b7573b58",
      "937955dcf56b4f5289d57f6f78833311",
      "dc049292c73c41b896336e584ca7f5be",
      "4c5bad7fc7214cec8a345b486ea4ff96",
      "8353bb2dedbf46cd8b715ff064493977",
      "6dbbcdcfbfa24206a66bb6520fce7524",
      "1d0894cd0c924bd8a20b781541bcabec",
      "901dc303270b498781d1702e8e701bcb",
      "083666449b294a8cb9b5614e2f08b989",
      "19582e4dea84449ab545d9acc1123260",
      "84b02a6fe362449698782f6ce3d06bca",
      "043f11e6101245afbc42edd5fa47c329",
      "15e790c7394b45d7a9186ad18c414894",
      "cd3dec6935e541639198a112a91365dd",
      "49219fe08f0c425e98e9c7ec2a44751e",
      "33cc0f1616b3452e8580781bdf8b65e0",
      "f543e93134614e1eac528ce5e04f3c11",
      "6e5380dd0319438a84bb5a0e37b753d6",
      "8d1dccdf883d42c382c9a16809883e54",
      "f000405093624eae85bc6d3762c15f4a",
      "938d44724cda40098d7b09d59fb2252f",
      "a60c929ae87041f7a09a274cb0dcd12d",
      "00bbf442ef1b48e2b81c3d705f9ac113",
      "12974cab7d8b46e7ac76965bbd84b807",
      "415ee5bd13c145d28b8dfd53eaaa483a",
      "fe16476bb24d490bb5d3cf6203b06373",
      "889f1b0140e84a7997caa22a593c18e1",
      "772e68f526d94cde9a2e4fcb110aee0d",
      "689b4c9bf0934ce6aeb6f1f7214c103a",
      "215e3262130c420ba01906556f67165c",
      "ff44c8f05c794e0f823e10de65ca6d7f",
      "b755d54fd2814b2ba11213c855d8387d",
      "3b23e2ead08c47c3be6a4844c2d7b072",
      "a3a781b652fd49a8a67e743c61f23ee1",
      "7211da2398ba46bbb83e0fef9ce5bc54",
      "9bd85e072ebf4fcbac2e81d152129a70",
      "95f7140c1d6e48a2a6426a2470bd391c",
      "3985945ec6c0409bb12080ba8e2121e3",
      "65c9da25fb3149f0b6a65cb3d8b73020",
      "f4b5344e60b04c53aac62ee7f20c8ce7",
      "eff96ba27ee84ddeb08c88a66b9892c5",
      "b1a344c341944201b240527ba1db279a",
      "67111a145e674a898e1713e6d42da602",
      "aa6896a2ddc140f39d3c69ae5c561519",
      "ae3ad12140214d50a284252876801869",
      "c4f6184e1d4041d28ee1883bbecf97c7",
      "b3cfcbf537b3420989df9c16db3c8a77",
      "6638b4e0fa7642a586addcae484a8d3f",
      "a7e7781d1eca43019060e4b90e1ab82f",
      "7a4fd5f5512f4d8b815f75d070d623be",
      "f63d944c3d124373abc74bab36a6fa8e",
      "2654cec33a91439c862c4f8693e5b591",
      "14ab8257c03648698b8e56f1526faf2b",
      "6f544625e6ca4f50838ec4d70e0e2b72",
      "7bed8bb7af7a4055825bd23f0da2d09d",
      "a8840578785e4eb082a307d0a92203d8",
      "ca436335a1a449569aad70ad4815ae1e"
     ]
    },
    "id": "bgPo-ZAWPsFi",
    "outputId": "a3701170-f48d-4972-8cf5-f093049138bc"
   },
   "outputs": [],
   "source": [
    "train_epochs = \"3ep\"  # Train for 3 epochs because we're assuming Colab environment and hardware\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"  # select the device\n",
    "\n",
    "trainer = composer.trainer.Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    max_duration=train_epochs,\n",
    "    device=device,\n",
    "    callbacks=[\n",
    "        checkpointsaver,\n",
    "        speedmonitor,\n",
    "        runtimeestimator,\n",
    "        lrmonitor,\n",
    "        optimizermonitor,\n",
    "        memorymonitor,\n",
    "        memorysnapshot,\n",
    "        oomobserver,\n",
    "        imagevisualiser,\n",
    "    ],\n",
    "    loggers=neptune_logger,\n",
    "    algorithms=algorithms,\n",
    ")\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p-PoOFSPsFh"
   },
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIzqE8dDPsFi"
   },
   "source": [
    "## Log additional metadata\n",
    "The `base_handler` property of `NeptuneLogger` exposes the [namespace handler](https://docs.neptune.ai/api/field_types/#namespace-handler) being used by the logger. You can use it to log any additional metadata in the base namespace.\n",
    "\n",
    "To learn more about namespaces, see [Namespace and fields](https://docs.neptune.ai/about/namespaces_and_fields/) in the Neptune docs.\n",
    "\n",
    "**Note:** The default base namespace used by `NeptuneLogger` is \"training\". You can update this by passing your own \"base_namespace\" while initializing `NeptuneLogger`.\n",
    "\n",
    "In the below example, we log a sample image from the training dataset to the \"training/sample_image\" namespace of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu1J6hw_PsFi"
   },
   "outputs": [],
   "source": [
    "from neptune.types import File\n",
    "\n",
    "neptune_logger.base_handler[\"sample_image\"].upload(File.as_image(train_dataset.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJrreEE5PsFi"
   },
   "source": [
    "## Log to your custom namespace\n",
    "If you want to log to a different namespace than the base one, you can use the `neptune_run` property of the `NeptuneLogger` instance to access the underlying Neptune `Run` object and pass your own namespaces.\n",
    "\n",
    "In the below example, we log a sample image from the eval dataset to the \"eval/sample_image\" namespace of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Quqqh5ezPsFi"
   },
   "outputs": [],
   "source": [
    "neptune_logger.neptune_run[\"eval/sample_image\"].upload(File.as_image(test_dataset.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuTf1oxEPsFi"
   },
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kaRdVZlPsFi",
    "outputId": "2d68ef9c-015d-4a98-fa71-70859a5db7b3"
   },
   "outputs": [],
   "source": [
    "trainer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIL4YStSelut"
   },
   "source": [
    "## Analyze run in the Neptune app\n",
    "To explore the logged metadata, follow the run link in the above cell output.\n",
    "You can also explore this [example run](https://app.neptune.ai/o/showcase/org/mosaicml-composer/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=Composer-run-overview-9b1f1fae-f543-41d1-a778-8604c9b6503d&shortId=MMLCOMP-6)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
