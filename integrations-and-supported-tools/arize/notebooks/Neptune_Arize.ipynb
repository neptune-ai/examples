{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arize integration guide\n",
    "Arize and Neptune are MLOps tools that aim to improve connected but related parts of your ML pipeline and workflow.\n",
    "\n",
    "Arize helps you:\n",
    "- visualize your production model performance\n",
    "- understand drift and data quality issues\n",
    "\n",
    "Neptune logs, stores, displays, and compares your model-building metadata for better experiment tracking and model registry.\n",
    "\n",
    "Together, Arize and Neptune help you:\n",
    "- Train the best model\n",
    "- Validate your model pre-launch\n",
    "- Compare production performances of those models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs.\n",
    "  1. Have Arize installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neptune neptune-sklearn arize pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "import neptune.integrations.sklearn as npt_utils\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "import os\n",
    "\n",
    "from arize.api import Client\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"neptune_cancer_prediction_model\"\n",
    "model_version = \"v1\"\n",
    "model_type = ModelTypes.BINARY_CLASSIFICATION\n",
    "\n",
    "\n",
    "def process_data(X, y):\n",
    "    X = np.array(X).reshape((len(X), 30))\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Load and split data\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X, y = X.astype(np.float32), y\n",
    "\n",
    "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log training and validation metadata to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Initialize a run\n",
    "run = neptune.init_run(project=\"common/showroom\", api_token=neptune.ANONYMOUS_API_TOKEN)\n",
    "\n",
    "# Model training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# (Neptune) Log model performance\n",
    "run[\"regression_summary\"] = npt_utils.create_classifier_summary(\n",
    "    model, X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# (Neptune) Log model parameters\n",
    "run[\"estimator/params\"] = stringify_unsupported(npt_utils.get_estimator_params(model))\n",
    "\n",
    "# (Neptune) Save model\n",
    "run[\"estimator/pickled-model\"] = npt_utils.get_pickled_model(model)\n",
    "\n",
    "# (Neptune) Log \"model_id\", for better reference\n",
    "run[\"model_id\"] = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log training and validation records to Arize\n",
    "\n",
    "Arize logs training and validation records to an Evaluation Store for model pre-launch validation, such as visualizing performance across different feature slices (for example, model accuracy for lower-income versus higher-income individuals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Arize) Initialize Arize client\n",
    "arize = Client(space_key=os.environ[\"ARIZE_SPACE_KEY\"], api_key=os.environ[\"ARIZE_API_KEY\"])\n",
    "\n",
    "# Generate model predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# (Arize) Logging training\n",
    "train_prediction_labels = pd.Series(y_train_pred, name=\"predicted_labels\")\n",
    "train_actual_labels = pd.Series(y_train, name=\"actual_labels\")\n",
    "train_feature_df = pd.DataFrame(X_train, columns=data[\"feature_names\"]).to_dict(\"list\")\n",
    "\n",
    "train_responses = arize.log(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    prediction_label=train_prediction_labels,\n",
    "    actual_label=train_actual_labels,\n",
    "    environment=Environments.TRAINING,\n",
    "    features=train_feature_df,\n",
    ")\n",
    "\n",
    "# (Arize) Logging validation\n",
    "val_prediction_labels = pd.Series(y_val_pred)\n",
    "val_actual_labels = pd.Series(y_val)\n",
    "val_features_df = pd.DataFrame(X_val, columns=data[\"feature_names\"]).to_dict(\"list\")\n",
    "\n",
    "val_responses = arize.log(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    batch_id=\"batch0\",\n",
    "    prediction_label=val_prediction_labels,\n",
    "    actual_label=val_actual_labels,\n",
    "    environment=Environments.VALIDATION,\n",
    "    features=val_features_df,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
