{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arize integration guide\n",
    "Arize and Neptune are MLOps tools that aim to improve connected but different parts of your ML pipeline and workflow.\n",
    "\n",
    "Arize helps you:\n",
    "- visualize your production model performance\n",
    "- understand drift and data quality issues\n",
    "\n",
    "Neptune logs, stores, displays, and compares your model-building metadata for better experiment tracking and model registry.\n",
    "\n",
    "Together, Arize and Neptune help you:\n",
    "- Train the best model\n",
    "- Validate your model pre-launch\n",
    "- Compare production performances of those models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs.\n",
    "  1. Have Arize installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neptune neptune-tensorflow-keras arize keras pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "from arize.api import Client\n",
    "from arize.utils.types import ModelTypes, Schema, Environments\n",
    "\n",
    "import glob\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"neptune_cancer_prediction_model\"\n",
    "model_version = \"v1\"\n",
    "model_type = ModelTypes.BINARY_CLASSIFICATION\n",
    "\n",
    "\n",
    "def process_data(X, y):\n",
    "    X = np.array(X).reshape((len(X), 30))\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Load data and split data\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X, y = X.astype(np.float32), y\n",
    "\n",
    "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "\n",
    "# Define and compile model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation=\"sigmoid\", input_shape=((30,))))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(20, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.mean_squared_logarithmic_error,\n",
    ")\n",
    "\n",
    "# Fit model and log callbacks\n",
    "params = {\n",
    "    \"batch_size\": 30,\n",
    "    \"epochs\": 50,\n",
    "    \"verbose\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log training and validation metadata to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Initialize a run\n",
    "run = neptune.init_run(project=\"common/showroom\", api_token=neptune.ANONYMOUS_API_TOKEN)\n",
    "\n",
    "callbacked = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    epochs=params[\"epochs\"],\n",
    "    verbose=params[\"verbose\"],\n",
    "    validation_data=(X_test, y_test),\n",
    "    # (Neptune) log to Neptune using a Neptune callback\n",
    "    callbacks=[NeptuneCallback(run=run)],\n",
    ")\n",
    "\n",
    "# Storing model version 1\n",
    "directory_name = f\"keras_model_{model_version}\"\n",
    "model.save(directory_name)\n",
    "\n",
    "run[f\"{directory_name}/saved_model.pb\"].upload(f\"{directory_name}/saved_model.pb\")\n",
    "\n",
    "for name in glob.glob(f\"{directory_name}/variables/*\"):\n",
    "    run[name].upload(name)\n",
    "\n",
    "# (Neptune) Log \"model_id\", for better reference\n",
    "run[\"model_id\"] = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log training and validation records to Arize\n",
    "\n",
    "Arize logs training and validation records to an Evaluation Store for model pre-launch validation, such as visualizing performance across different feature slices (for example, model accuracy for lower-income versus higher-income individuals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Arize) Initialize Arize client\n",
    "arize = Client(space_key=os.environ[\"ARIZE_SPACE_KEY\"], api_key=os.environ[\"API_KEY\"])\n",
    "\n",
    "# Generate model predictions\n",
    "y_train_pred = model.predict(X_train).T[0]\n",
    "y_val_pred = model.predict(X_val).T[0]\n",
    "y_test_pred = model.predict(X_test).T[0]\n",
    "\n",
    "# (Arize) Logging training\n",
    "train_prediction_labels = pd.Series(y_train_pred, name=\"predicted_labels\")\n",
    "train_actual_labels = pd.Series(y_train, name=\"actual_labels\")\n",
    "train_feature_df = pd.DataFrame(X_train, columns=data[\"feature_names\"]).to_dict(\"list\")\n",
    "\n",
    "train_responses = arize.log(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    prediction_label=train_prediction_labels,\n",
    "    actual_label=train_actual_labels,\n",
    "    environment=Environments.TRAINING,\n",
    "    features=train_feature_df,\n",
    ")\n",
    "\n",
    "# (Arize) Logging validation\n",
    "val_prediction_labels = pd.Series(y_val_pred)\n",
    "val_actual_labels = pd.Series(y_val)\n",
    "val_features_df = pd.DataFrame(X_val, columns=data[\"feature_names\"]).to_dict(\"list\")\n",
    "\n",
    "val_responses = arize.log(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    batch_id=\"batch0\",\n",
    "    prediction_label=val_prediction_labels,\n",
    "    actual_label=val_actual_labels,\n",
    "    environment=Environments.VALIDATION,\n",
    "    features=val_features_df,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
