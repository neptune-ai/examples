{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EYNlatILeluO"
   },
   "source": [
    "![Neptune + Evidently](https://neptune.ai/wp-content/uploads/2023/09/evidently.svg)\n",
    "\n",
    "# Neptune + Evidently\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/evidently/notebooks/Neptune_Evidently.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/evidently/notebooks/Neptune_Evidently.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/evidently-support/runs/table?viewId=9b014afd-cdc8-4f08-9d0f-70b343e7f4d2&detailsTab=dashboard&dashboardId=9917f940-757a-424d-879e-7781a00bf0c3&shortId=EV-7&type=run\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/evidently/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zY6B8JTKeluQ",
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "[Evidently](https://www.evidentlyai.com/) is an open-source tool to evaluate, test, and monitor machine learning models.\n",
    "This guide will show you how to:\n",
    "\n",
    "* Upload Evidently's interactive reports to Neptune,\n",
    "* Log report values as key-value pairs in Neptune, \n",
    "* Log and visualize production data drift using Evidently and Neptune."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EiPydbIreluR"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NTVvWzR-eluS"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7S4oP2QneluT",
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -U evidently neptune pandas scikit-learn\n",
    "%pip install -U --user scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I9FI9oaqeluU",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CrsGX17eluV",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log reports\n",
    "\n",
    "This section shows how you can log Evidently test suites and reports to Neptune.  \n",
    "You can find the entire list of pretests in the [Evidently documentation](https://docs.evidentlyai.com/presets/all-presets)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_frame = datasets.load_iris(as_frame=True).frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evidently test suites and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stability = TestSuite(\n",
    "    tests=[\n",
    "        DataStabilityTestPreset(),\n",
    "    ]\n",
    ")\n",
    "data_stability.run(\n",
    "    current_data=iris_frame.iloc[:60], reference_data=iris_frame.iloc[60:], column_mapping=None\n",
    ")\n",
    "data_stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_report = Report(\n",
    "    metrics=[\n",
    "        DataDriftPreset(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_drift_report.run(\n",
    "    current_data=iris_frame.iloc[:60], reference_data=iris_frame.iloc[60:], column_mapping=None\n",
    ")\n",
    "data_drift_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/evidently-support](https://app.neptune.ai/o/common/org/evidently-support). **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    tags=[\"reports\"],  # (optional) replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app.\n",
    "\n",
    "    To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/evidently-support\",\n",
    "    tags=[\"reports\"],  # (optional) replace with your own\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Save reports as HTML\n",
    "\n",
    "Using Neptune's HTML previewer, you can view and interact with Evidently's rich HTML reports on Neptune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stability.save_html(\"data_stability.html\")\n",
    "data_drift_report.save_html(\"data_drift_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"data_stability/report\"].upload(\"data_stability.html\")\n",
    "run[\"data_drift/report\"].upload(\"data_drift_report.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Save reports as dict\n",
    "By saving Evidently's results as a dictionary to Neptune, you can have programmatic access to them to use in your CI/CD pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "run[\"data_stability\"] = stringify_unsupported(data_stability.as_dict())\n",
    "run[\"data_drift\"] = stringify_unsupported(data_drift_report.as_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze logged reports in the Neptune app\n",
    "\n",
    "Explore the run (reports, dictionaries) in the Neptune app, or check this [example dashboard](https://app.neptune.ai/o/common/org/evidently-support/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=9917f940-757a-424d-879e-7781a00bf0c3&shortId=EV-7&type=run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log production data drift\n",
    "This section shows how you can use Evidently to evaluate production data drift and log the results to Neptune."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip --create-dirs -o data/Bike-Sharing-Dataset.zip\n",
    "! unzip -o data/Bike-Sharing-Dataset.zip -d data\n",
    "\n",
    "bike_df = pd.read_csv(\"data/hour.csv\")\n",
    "bike_df[\"datetime\"] = pd.to_datetime(bike_df[\"dteday\"])\n",
    "bike_df[\"datetime\"] += pd.to_timedelta(bike_df.hr, unit=\"h\")\n",
    "bike_df.set_index(\"datetime\", inplace=True)\n",
    "bike_df = bike_df[\n",
    "    [\n",
    "        \"season\",\n",
    "        \"holiday\",\n",
    "        \"workingday\",\n",
    "        \"weathersit\",\n",
    "        \"temp\",\n",
    "        \"atemp\",\n",
    "        \"hum\",\n",
    "        \"windspeed\",\n",
    "        \"casual\",\n",
    "        \"registered\",\n",
    "        \"cnt\",\n",
    "    ]\n",
    "]\n",
    "bike_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we treat this data as the input data for a live model. To use with production models, the prediction logs should be available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define column mapping for Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "\n",
    "data_columns = ColumnMapping()\n",
    "data_columns.numerical_features = [\"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\"]\n",
    "data_columns.categorical_features = [\"holiday\", \"workingday\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define what to log\n",
    "Specify which metrics you want to calculate. In this case, you can generate the Data Drift report and log the drift score for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_drift(reference, production, column_mapping):\n",
    "    data_drift_report = Report(metrics=[DataDriftPreset()])\n",
    "    data_drift_report.run(\n",
    "        reference_data=reference, current_data=production, column_mapping=column_mapping\n",
    "    )\n",
    "    report = data_drift_report.as_dict()\n",
    "\n",
    "    drifts = []\n",
    "\n",
    "    for feature in column_mapping.numerical_features + column_mapping.categorical_features:\n",
    "        drifts.append(\n",
    "            (feature, report[\"metrics\"][1][\"result\"][\"drift_by_columns\"][feature][\"drift_score\"])\n",
    "        )\n",
    "\n",
    "    return drifts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the comparison windows\n",
    "\n",
    "Specify the period that is considered reference: Evidently will use it as the base for the comparison. Then, you should choose the periods to treat as experiments. This emulates the production model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reference dates\n",
    "reference_dates = (\"2011-01-01 00:00:00\", \"2011-06-30 23:00:00\")\n",
    "\n",
    "# Set experiment batches dates\n",
    "experiment_batches = [\n",
    "    (\"2011-07-01 00:00:00\", \"2011-07-31 00:00:00\"),\n",
    "    (\"2011-08-01 00:00:00\", \"2011-08-31 00:00:00\"),\n",
    "    (\"2011-09-01 00:00:00\", \"2011-09-30 00:00:00\"),\n",
    "    (\"2011-10-01 00:00:00\", \"2011-10-31 00:00:00\"),\n",
    "    (\"2011-11-01 00:00:00\", \"2011-11-30 00:00:00\"),\n",
    "    (\"2011-12-01 00:00:00\", \"2011-12-31 00:00:00\"),\n",
    "    (\"2012-01-01 00:00:00\", \"2012-01-31 00:00:00\"),\n",
    "    (\"2012-02-01 00:00:00\", \"2012-02-29 00:00:00\"),\n",
    "    (\"2012-03-01 00:00:00\", \"2012-03-31 00:00:00\"),\n",
    "    (\"2012-04-01 00:00:00\", \"2012-04-30 00:00:00\"),\n",
    "    (\"2012-05-01 00:00:00\", \"2012-05-31 00:00:00\"),\n",
    "    (\"2012-06-01 00:00:00\", \"2012-06-30 00:00:00\"),\n",
    "    (\"2012-07-01 00:00:00\", \"2012-07-31 00:00:00\"),\n",
    "    (\"2012-08-01 00:00:00\", \"2012-08-31 00:00:00\"),\n",
    "    (\"2012-09-01 00:00:00\", \"2012-09-30 00:00:00\"),\n",
    "    (\"2012-10-01 00:00:00\", \"2012-10-31 00:00:00\"),\n",
    "    (\"2012-11-01 00:00:00\", \"2012-11-30 00:00:00\"),\n",
    "    (\"2012-12-01 00:00:00\", \"2012-12-31 00:00:00\"),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Run and log drifts to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "custom_run_id = str(uuid.uuid4())\n",
    "\n",
    "for date in experiment_batches:\n",
    "    with neptune.init_run(\n",
    "        api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "        project=\"common/evidently-support\",\n",
    "        custom_run_id=custom_run_id,  # Passing a custom run ID ensures that the metrics are logged to the same run.\n",
    "        tags=[\"prod monitoring\"],  # (optional) replace with your own\n",
    "    ) as run:\n",
    "        metrics = eval_drift(\n",
    "            bike_df.loc[reference_dates[0] : reference_dates[1]],\n",
    "            bike_df.loc[date[0] : date[1]],\n",
    "            column_mapping=data_columns,\n",
    "        )\n",
    "\n",
    "        for feature in metrics:\n",
    "            run[\"drift\"][feature[0]].append(\n",
    "                round(feature[1], 3),\n",
    "                timestamp=datetime.strptime(date[0], \"%Y-%m-%d %H:%M:%S\").timestamp(),\n",
    "            )\n",
    "            # Passing a timestamp in the append methods lets you visualize the date in the x-axis of the charts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HIL4YStSelut",
    "tags": [
     "header"
    ]
   },
   "source": [
    "### Analyze logged drifts in the Neptune app\n",
    "Go to the run link and explore the drifts in the **Charts** dashboard. You might have to change the x-axis from **Step** to **Time (absolute)**.\n",
    "You can also explore this [example Drifts dashboard](https://app.neptune.ai/o/common/org/evidently-support/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=9918072b-90f2-4963-a3a1-e857acd6e65c&shortId=EV-8&type=run)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
