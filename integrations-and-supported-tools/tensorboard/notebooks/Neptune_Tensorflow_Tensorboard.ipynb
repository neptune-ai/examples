{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GG3_2HyRVY4Y",
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "![Neptune + TensorBoard](https://neptune.ai/wp-content/uploads/2023/09/tensorboard_tensorflow.svg)\n",
    "\n",
    "# Neptune + TensorBoard (Tensorflow)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/tensorboard/notebooks/Neptune_Tensorflow_Tensorboard.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/tensorboard/notebooks/Neptune_Tensorflow_Tensorboard.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/tensorboard-integration/runs/details?viewId=standard-view&detailsTab=metadata&shortId=TBOARD-880&type=run\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/tensorboard/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>\n",
    "\n",
    "Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Use the `enable_tensorboard_logging()` function to log metrics and metadata to both TensorBoard and Neptune\n",
    "* Export previous Tensorboard logs to Neptune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FUaDrmRu-h3k"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "w_0KXqlePqNi"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i36OvZAgvxkj"
   },
   "outputs": [],
   "source": [
    "%pip install -U neptune[tensorboard]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rik2HDr0r5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in a public project. **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMdpj-Se4t0U",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,  # replace with your own\n",
    "    project=\"common/tensorboard-integration\",  # replace with your own\n",
    "    tags=[\"notebook\", \"sync\"],  # optional\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q3Hm8xjsr5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from neptune_tensorboard import enable_tensorboard_logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Neptune integration with TensorBoard to log to both Neptune and TensorBoard\n",
    "Calling `enable_tensorboard_logging()` also works with SummaryWriter from PyTorch and tensorboardX and also `Tensorboard` callback for Keras.\n",
    "__NOTE:__ This will log to both the `tensorboard` directory and the Neptune run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_tensorboard_logging(run)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create default writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer(\"logs\")\n",
    "writer.set_as_default(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\")\n",
    "with open(\"mnist.npz\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "\n",
    "with np.load(\"mnist.npz\") as data:\n",
    "    train_examples = data[\"x_train\"]\n",
    "    train_labels = data[\"y_train\"]\n",
    "    test_examples = data[\"x_test\"]\n",
    "    test_labels = data[\"y_test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT-fWITQxJMw"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"shuffle_buffer_size\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 5,\n",
    "    \"num_visualization_examples\": 10,\n",
    "}\n",
    "\n",
    "# Log training parameters\n",
    "for name, value in params.items():\n",
    "    tf.summary.scalar(name, value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for training\n",
    "def normalize_img(image):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "train_examples = normalize_img(train_examples)\n",
    "test_examples = normalize_img(test_examples)\n",
    "\n",
    "# Prepare data for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(params[\"shuffle_buffer_size\"]).batch(params[\"batch_size\"])\n",
    "test_dataset = test_dataset.batch(params[\"batch_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(params[\"lr\"])\n",
    "\n",
    "# Log model summary\n",
    "with io.StringIO() as s:\n",
    "    model.summary(print_fn=lambda x: s.write(x + \"\\n\"))\n",
    "    model_summary = s.getvalue()\n",
    "\n",
    "tf.summary.text(\"model_summary\", model_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for training loop\n",
    "def loss_and_preds(model, x, y, training):\n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_pred = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_pred), y_pred\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value, _ = loss_and_preds(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params[\"num_epochs\"]):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    for x, y in train_dataset:\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "    # Log metrics for the epoch\n",
    "    # Train metrics\n",
    "    tf.summary.scalar(\"loss\", epoch_loss_avg.result())\n",
    "    tf.summary.scalar(\"accuracy\", epoch_accuracy.result())\n",
    "\n",
    "    # Log test metrics\n",
    "    test_loss, test_preds = loss_and_preds(model, test_examples, test_labels, False)\n",
    "    test_acc = epoch_accuracy(test_labels, test_preds)\n",
    "    tf.summary.scalar(\"test_loss\", test_loss)\n",
    "    tf.summary.scalar(\"test_accuracy\", test_acc)\n",
    "\n",
    "    # Log test prediction\n",
    "    for idx in range(params[\"num_visualization_examples\"]):\n",
    "        np_image = test_examples[idx].numpy().reshape(1, 28, 28, 1)\n",
    "        pred_label = test_preds[idx].numpy().argmax()\n",
    "        true_label = test_labels[idx]\n",
    "        tf.summary.image(f\"epoch-{epoch}_pred-{pred_label}_actual-{true_label}\", np_image)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == (params[\"num_epochs\"] - 1):\n",
    "        print(\n",
    "            \"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(\n",
    "                epoch, epoch_loss_avg.result(), epoch_accuracy.result()\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XSHLD6AkI7LW"
   },
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgh3NwDoJAuG"
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mRhOAcS0Q7Mm",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "Follow the run link to explore the logged metadata (metrics, params, predictions) in Neptune.\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/o/common/org/tensorboard-integration/runs/details?viewId=standard-view&detailsTab=metadata&shortId=TBOARD-880&type=run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting previous TensorBoard Logs\n",
    "Export previous logs in the `logs` directory with the `neptune tensorboard` command via CLI.\n",
    "__NOTE:__ Passing the `api_token` and `project` arguments can be skipped if the corresponding environment variables are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !neptune tensorboard --api_token API_TOKEN --project PROJECT_NAME logs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
