{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG3_2HyRVY4Y",
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "# Neptune + PyTorch\n",
    "\n",
    "Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Create a NeptuneLogger()\n",
    "* Log training metrics to Neptune using NeptuneLogger()\n",
    "* Upload model checkpoints to Neptune using NeptuneLogger()\n",
    "* Log model predictions to Neptune using NeptuneLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUaDrmRu-h3k"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "* If you're running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example logged to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_0KXqlePqNi"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i36OvZAgvxkj"
   },
   "outputs": [],
   "source": [
    "\n",
    "! pip install neptune[pytorch] torch torchvision numpy torchviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rik2HDr0r5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, we tell Neptune:\n",
    "* **Who you are** - with your Neptune API token\n",
    "* **Where to send the metadata** - to your Neptune project\n",
    "\n",
    "For example, if your workspace name is `ml-team` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**.\n",
    "\n",
    "### Haven't registered yet?\n",
    "\n",
    "To log anonymously to a public project, replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "\n",
    "run = neptune.init_run(project=\"common/pytorch-integration\", api_token=neptune.ANONYMOUS_API_TOKEN)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMdpj-Se4t0U",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/pytorch-integration\",  # replace with your own\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3Hm8xjsr5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "You now have new run in Neptune! From here on, we'll use the `run` object to log metadata.\n",
    "\n",
    "**To open the run in Neptune, click on the link that appeared in the cell output.**\n",
    "\n",
    "There's not much to display yet, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT-fWITQxJMw"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"bs\": 128,\n",
    "    \"input_sz\": 32 * 32 * 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"epochs\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_model = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.seq_model(x)\n",
    "\n",
    "\n",
    "model = Model(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(\n",
    "    parameters[\"device\"]\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and transform the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/CIFAR10\"\n",
    "compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=parameters[\"bs\"], shuffle=True, num_workers=0\n",
    ")\n",
    "validset = datasets.CIFAR10(data_dir, train=False, transform=data_tfms[\"train\"], download=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=parameters[\"bs\"], num_workers=0)\n",
    "\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Create NeptuneLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_pytorch import NeptuneLogger\n",
    "\n",
    "npt_logger = NeptuneLogger(\n",
    "    run, model=model, log_model_diagram=True, log_gradients=True, log_parameters=True, log_freq=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "# (Neptune) The base_namespace attribute of the logger can be used to log metadata consistently\n",
    "# under the 'base_namespace' namespace.\n",
    "run[npt_logger.base_namespace][\"hyperparams\"] = stringify_unsupported(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log metrics while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(parameters[\"epochs\"]):\n",
    "    for i, (x, y) in enumerate(trainloader, 0):\n",
    "        x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "        # Log after every 30 steps\n",
    "        if i % 30 == 0:\n",
    "            run[npt_logger.base_namespace][\"batch/loss\"].append(loss.item())\n",
    "            run[npt_logger.base_namespace][\"batch/acc\"].append(acc.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Checkpoint number is automatically incremented on subsequent call.\n",
    "    # Call 1 -> ckpt_1.pt\n",
    "    # Call 2 -> ckpt_2.pt\n",
    "    # npt_logger.save_checkpoint()  # uncomment to save checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log prediction from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.types import File\n",
    "\n",
    "dataiter = iter(validloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Predict batch of n_samples\n",
    "n_samples = 10\n",
    "imgs = images[:n_samples].to(parameters[\"device\"])\n",
    "probs = torch.nn.functional.softmax(model(imgs), dim=1)\n",
    "\n",
    "# Decode probs and Log tensors as image\n",
    "for i, ps in enumerate(probs):\n",
    "    pred = classes[torch.argmax(ps)]\n",
    "    ground_truth = classes[labels[i]]\n",
    "    description = f\"pred: {pred} | ground truth: {ground_truth}\"\n",
    "\n",
    "    # Log Series of Tensors as Image and Predictions.\n",
    "    run[npt_logger.base_namespace][\"predictions\"].append(\n",
    "        File.as_image(imgs[i].cpu().squeeze().permute(2, 1, 0).clip(0, 1)),\n",
    "        name=f\"{i}_{pred}_{ground_truth}\",\n",
    "        description=description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qagCeeazjrW"
   },
   "source": [
    "### (Neptune) Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C36-L8cUzjrW"
   },
   "outputs": [],
   "source": [
    "# Save final model as \"model.pt\"\n",
    "# npt_logger.save_model(\"model\")  # uncomment to save final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSHLD6AkI7LW"
   },
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgh3NwDoJAuG"
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRhOAcS0Q7Mm",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "Go to the run link and explore metadata (metrics, params, predictions) that were logged to the run in Neptune.\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/o/common/org/pytorch-integration/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=Training-Overview-9920962e-ff6a-4dea-b551-88006799b116&shortId=PYTOR1-7046)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
