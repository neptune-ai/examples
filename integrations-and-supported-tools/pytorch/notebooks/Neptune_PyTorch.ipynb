{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GG3_2HyRVY4Y",
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "![Neptune + PyTorch](https://neptune.ai/wp-content/uploads/2023/09/pytorch.svg)\n",
    "\n",
    "# Neptune + PyTorch\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/pytorch/notebooks/Neptune_PyTorch.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/pytorch/notebooks/Neptune_PyTorch.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/pytorch-integration/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=9920962e-ff6a-4dea-b551-88006799b116&shortId=PYTOR1-7411&type=run\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/pytorch/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>\n",
    "\n",
    "Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Create a NeptuneLogger()\n",
    "* Log training metrics to Neptune using NeptuneLogger()\n",
    "* Upload model checkpoints to Neptune using NeptuneLogger()\n",
    "* Log model predictions to Neptune using NeptuneLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FUaDrmRu-h3k"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "w_0KXqlePqNi"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i36OvZAgvxkj"
   },
   "outputs": [],
   "source": [
    "%pip install -U neptune neptune-pytorch numpy torch torchvision torchviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rik2HDr0r5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in a public project. **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMdpj-Se4t0U",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,  # replace with your own\n",
    "    project=\"common/pytorch-integration\",  # replace with your own\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q3Hm8xjsr5Hn",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT-fWITQxJMw"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"bs\": 128,\n",
    "    \"input_sz\": 32 * 32 * 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"epochs\": 2,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_model = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.seq_model(x)\n",
    "\n",
    "\n",
    "model = Model(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(\n",
    "    parameters[\"device\"]\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and transform the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/CIFAR10\"\n",
    "compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=parameters[\"bs\"], shuffle=True, num_workers=0\n",
    ")\n",
    "validset = datasets.CIFAR10(data_dir, train=False, transform=data_tfms[\"train\"], download=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=parameters[\"bs\"], num_workers=0)\n",
    "\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Create NeptuneLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_pytorch import NeptuneLogger\n",
    "\n",
    "npt_logger = NeptuneLogger(\n",
    "    run, model=model, log_model_diagram=True, log_gradients=True, log_parameters=True, log_freq=30\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "# (Neptune) The base_namespace attribute of the logger can be used to log metadata consistently\n",
    "# under the 'base_namespace' namespace.\n",
    "run[npt_logger.base_namespace][\"hyperparams\"] = stringify_unsupported(parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log metrics while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(parameters[\"epochs\"]):\n",
    "    for i, (x, y) in enumerate(trainloader, 0):\n",
    "        x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "        # Log after every 30 steps\n",
    "        if i % 30 == 0:\n",
    "            run[npt_logger.base_namespace][\"batch/loss\"].append(loss.item())\n",
    "            run[npt_logger.base_namespace][\"batch/acc\"].append(acc.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Checkpoint number is automatically incremented on subsequent call.\n",
    "    # Call 1 -> ckpt_1.pt\n",
    "    # Call 2 -> ckpt_2.pt\n",
    "    # npt_logger.log_checkpoint()  # uncomment to log model checkpoints to the run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Log prediction from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.types import File\n",
    "\n",
    "dataiter = iter(validloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Predict batch of n_samples\n",
    "n_samples = 10\n",
    "imgs = images[:n_samples].to(parameters[\"device\"])\n",
    "probs = torch.nn.functional.softmax(model(imgs), dim=1)\n",
    "\n",
    "# Decode probs and Log tensors as image\n",
    "for i, ps in enumerate(probs):\n",
    "    pred = classes[torch.argmax(ps)]\n",
    "    ground_truth = classes[labels[i]]\n",
    "    description = f\"pred: {pred} | ground truth: {ground_truth}\"\n",
    "\n",
    "    # Log Series of Tensors as Image and Predictions.\n",
    "    run[npt_logger.base_namespace][\"predictions\"].append(\n",
    "        File.as_image(imgs[i].cpu().squeeze().permute(2, 1, 0).clip(0, 1)),\n",
    "        name=f\"{i}_{pred}_{ground_truth}\",\n",
    "        description=description,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5qagCeeazjrW"
   },
   "source": [
    "### (Neptune) Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C36-L8cUzjrW"
   },
   "outputs": [],
   "source": [
    "# Log final model as \"model.pt\"\n",
    "# npt_logger.log_model(\"model\")  # uncomment to log the final model to the run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XSHLD6AkI7LW"
   },
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgh3NwDoJAuG"
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mRhOAcS0Q7Mm",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "Go to the run link and explore metadata (metrics, params, predictions) that were logged to the run in Neptune.\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/o/common/org/pytorch-integration/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=9920962e-ff6a-4dea-b551-88006799b116&shortId=PYTOR1-7411&type=run)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
