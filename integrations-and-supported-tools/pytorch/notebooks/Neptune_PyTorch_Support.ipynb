{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THIzFFk81nme"
   },
   "source": [
    "# Neptune + PyTorch\n",
    "\n",
    "## Before you start\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54CFqKRANLK5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install neptune-client numpy==1.19.5 torch==1.8.1 torchvision==0.10.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90-k5eK205uM"
   },
   "source": [
    "# Basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXve6tFt1dLd"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1NVL5h6MlLq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import neptune.new as neptune\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfqmkNLB1SRu"
   },
   "source": [
    "## Step 1: Create a Neptune *Run*\n",
    "\n",
    "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
    "\n",
    "To make this example easy to follow, we have created a public project **'common/optuna-integration'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
    "\n",
    "**(Optional)** To log to your Neptune project:\n",
    "\n",
    "* [Create a Neptune account](https://app.neptune.ai/register/)\n",
    "\n",
    "* [Find your API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "* [Find your project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "\n",
    "Pass your credentials to project and api_token arguments of neptune.init()\n",
    "\n",
    "`run = neptune.init(api_token='<YOUR_API_TOKEN>', project='<YOUR_WORKSPACE/YOUR_PROJECT>')` # pass your credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIAK4NasfQ_f",
    "outputId": "f0e5d8d5-278e-4d72-cb0f-3703fb60e9f6"
   },
   "outputs": [],
   "source": [
    "run = neptune.init(project = 'common/pytorch-integration', tags='Colab Notebook', api_token='ANONYMOUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4StPQOmmh_d"
   },
   "source": [
    "Running this cell creates a Run in Neptune, and you can log model building metadata to it.\n",
    "\n",
    "**Click on the link above to open the Run in Neptune UI.** For now, it is empty, but you should keep the tab open to see what happens next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WbPjLDk1GcC"
   },
   "source": [
    "## Step 2: Log config and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVJKNQxIYPAC"
   },
   "source": [
    "### Log Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_8vefGCNBIJ"
   },
   "outputs": [],
   "source": [
    "parameters = {'lr': 1e-2,\n",
    "              'bs': 128,\n",
    "              'input_sz': 32 * 32 * 3,\n",
    "              'n_classes': 10,\n",
    "              'model_filename': 'basemodel',\n",
    "              'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0Ig4exNSMwE"
   },
   "outputs": [],
   "source": [
    "run['config/hyperparameters'] = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2rAXguq0_IZ"
   },
   "source": [
    "### Log Config\n",
    "Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwdf0rrklZWi"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32* 32 * 3)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i19Y0g3YGvV2"
   },
   "outputs": [],
   "source": [
    "model = BaseModel(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(parameters[\"device\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viTM9XYl4-C0"
   },
   "source": [
    "Log model, criterion and optimizer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iZSQE5DYyqX"
   },
   "outputs": [],
   "source": [
    "run[\"config/model\"] = type(model).__name__\n",
    "run[\"config/criterion\"] = type(criterion).__name__\n",
    "run[\"config/optimizer\"] = type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2gKRp-8THxa"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/CIFAR10'\n",
    "compressed_ds = './data/CIFAR10/cifar-10-python.tar.gz'\n",
    "data_tfms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            \n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "b3b6f568bdd74e02a3b4af71fc45b14a",
      "0b984a82a839487781f05e42aac4b13c",
      "19ef8d7b71cc4a95b576c9be32ea3f76",
      "7664a9d0abda44c2b0b0ea487eca91c1",
      "a0637cc0d2dd449889d3d5a8e2a161ec",
      "f57fdc29215f4404b36e1cc0036436d2",
      "741c672a9187432ab63a757659232bcd",
      "0ede1aff20bb449c8c2f391f2fb5864d"
     ]
    },
    "id": "oMa-mrc64qjz",
    "outputId": "6d9e9b7e-297d-4278-da08-6c50cdac4b86"
   },
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms['train'], \n",
    "                            download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=parameters['bs'],\n",
    "                                          shuffle=True, num_workers=2)\n",
    "validset = datasets.CIFAR10(data_dir, train=False,\n",
    "                            transform=data_tfms['train'],\n",
    "                            download=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, \n",
    "                                          batch_size=parameters['bs'], \n",
    "                                          num_workers=2)\n",
    "      \n",
    "dataset_size = {'train': len(trainset), 'val': len(validset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mXZEVnl4-C1"
   },
   "source": [
    "Log dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKFjiUDqgTqT"
   },
   "outputs": [],
   "source": [
    "run[\"config/dataset/path\"] = data_dir\n",
    "run[\"config/dataset/transforms\"] = data_tfms\n",
    "run[\"config/dataset/size\"] = dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRaqN0ug1KP_"
   },
   "source": [
    "## Step 3: Log losses and metrics \n",
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgGfdruzNB3t"
   },
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(trainloader, 0):\n",
    "    x, y = x.to(parameters['device']), y.to(parameters['device'])\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(x)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, y)\n",
    "    acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "    run[\"training/batch/loss\"].log(loss)\n",
    "    \n",
    "    run[\"training/batch/acc\"].log(acc)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mMjQTFbUgZq"
   },
   "source": [
    "# More Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOfczeu6loOK"
   },
   "source": [
    "## Step 4: Log model arch and weights\n",
    "You need to have saved these files to disk using a helper function like save_model before trying to upload to neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFkn6KKK4-C1"
   },
   "outputs": [],
   "source": [
    "fname = parameters[\"model_filename\"]\n",
    "\n",
    "# Saving model architecture to .txt\n",
    "with open(f\"./{fname}_arch.txt\", \"w\") as f:  \n",
    "    f.write(str(model))\n",
    "    \n",
    "# Saving model weights .pth\n",
    "torch.save(model.state_dict(), f\"./{fname}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emMQ4KIXllN5"
   },
   "outputs": [],
   "source": [
    "run[f\"io_files/artifacts/{parameters['model_filename']}_arch\"].upload(f\"./{parameters['model_filename']}_arch.txt\")\n",
    "run[f\"io_files/artifacts/{parameters['model_filename']}\"].upload(f\"./{parameters['model_filename']}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxnCGtFaNxRC"
   },
   "source": [
    "## Step 5: Log images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqkTf7YZTEG6"
   },
   "source": [
    "### Log Torch Tensors as images\n",
    "You can log PyTorch Tensors (2d or 3d) directly from the memory, and have them visualized as an image. For more about logging torch tensor see [what you can log and display](https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#pytorch-tensor)\n",
    "and [field types](https://docs.neptune.ai/api-reference/field-types#fileseries) to understand how to upload multiple files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a9vqgOB4-C2"
   },
   "source": [
    "* Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tuNzGBatA-L"
   },
   "outputs": [],
   "source": [
    "from neptune.new.types import File\n",
    "import torch.nn.functional as F\n",
    "\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "dataiter = iter(validloader)\n",
    "images, labels = dataiter.next()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available(): model.to(\"cpu\")\n",
    "\n",
    "n_samples = 50\n",
    "img = images[:n_samples]\n",
    "probs = F.softmax(model(img),dim=1)\n",
    "probs = probs.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PDdbuhV4-C2"
   },
   "source": [
    "*  Decode probs and Log images tensors\n",
    "*  Log Series of Tensors as Image and Predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iqa2yfe4-C2"
   },
   "outputs": [],
   "source": [
    "for i, ps in enumerate(probs):\n",
    "    pred = classes[np.argmax(ps)]\n",
    "    gt = classes[labels[i]]\n",
    "    description = \"\\n\".join([\"class {}: {}%\".format(classes[n], round(p*100, 2)) for n, p in enumerate(ps)])\n",
    "    \n",
    "    run['images/predictions'].log(File.as_image(img[i].squeeze().permute(2,1,0).clip(0,1)), name=f'{i}_{pred}_{gt}', description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhE6C9xv-lXK"
   },
   "source": [
    "# Stop run\n",
    "\n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Meg02T9p9314",
    "outputId": "2e8f1ceb-b376-4ad1-80aa-bee415bf2237",
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_PyTorch_Support.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (neptune)",
   "language": "python",
   "name": "neptune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}