{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Initialize Neptune and create a `run`,\n",
    "* Log run configuration and metrics to Neptune,\n",
    "* Log model hyperparameters, architecture, and weights to Neptune,\n",
    "* Log torch tensors as images to Neptune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -U neptune numpy torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Neptune *run*\n",
    "\n",
    "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
    "\n",
    "To make this example easy to follow, we have created a public project **'common/optuna-integration'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
    "\n",
    "**(Optional)** To log to your Neptune project:\n",
    "\n",
    "* [Create a Neptune account](https://app.neptune.ai/register/)\n",
    "\n",
    "* [Find your API token](https://docs.neptune.ai/setup/setting_api_token/)\n",
    "* [Find your project name](https://docs.neptune.ai/setup/setting_project_name/)\n",
    "\n",
    "Pass your credentials to project and api_token arguments of neptune.init_run()\n",
    "\n",
    "`run = neptune.init_run(api_token=\"YOUR_API_TOKEN\", project=\"YOUR_WORKSPACE/YOUR_PROJECT\")` # pass your credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"common/pytorch-integration\",\n",
    "    tags=\"Colab Notebook\",\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell creates a run in Neptune, and you can log model building metadata to it.\n",
    "\n",
    "**Click on the link above to open the run in Neptune app.** For now, it is empty, but you should keep the tab open to see what happens next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"bs\": 128,\n",
    "    \"input_sz\": 32 * 32 * 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "run[\"config/hyperparameters\"] = stringify_unsupported(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Config\n",
    "Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(\n",
    "    parameters[\"device\"]\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log model, criterion and optimizer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"config/model\"] = type(model).__name__\n",
    "run[\"config/criterion\"] = type(criterion).__name__\n",
    "run[\"config/optimizer\"] = type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/CIFAR10\"\n",
    "compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=parameters[\"bs\"], shuffle=True, num_workers=0\n",
    ")\n",
    "validset = datasets.CIFAR10(data_dir, train=False, transform=data_tfms[\"train\"], download=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=parameters[\"bs\"], num_workers=0)\n",
    "\n",
    "dataset_size = {\"train\": len(trainset), \"val\": len(validset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"config/dataset/path\"] = data_dir\n",
    "run[\"config/dataset/transforms\"] = stringify_unsupported(data_tfms)\n",
    "run[\"config/dataset/size\"] = dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log losses and metrics \n",
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(trainloader, 0):\n",
    "    x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(x)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, y)\n",
    "    acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "    run[\"training/batch/loss\"].append(loss)\n",
    "\n",
    "    run[\"training/batch/acc\"].append(acc)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log model architecture and weights\n",
    "You need to have saved these files to disk using a helper function like save_model before trying to upload to neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = parameters[\"model_filename\"]\n",
    "\n",
    "# Saving model architecture to .txt\n",
    "with open(f\"./{fname}_arch.txt\", \"w\") as f:\n",
    "    f.write(str(model))\n",
    "\n",
    "# Saving model weights .pth\n",
    "torch.save(model.state_dict(), f\"./{fname}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[f\"io_files/artifacts/{parameters['model_filename']}_arch\"].upload(\n",
    "    f\"./{parameters['model_filename']}_arch.txt\"\n",
    ")\n",
    "run[f\"io_files/artifacts/{parameters['model_filename']}\"].upload(\n",
    "    f\"./{parameters['model_filename']}.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log images \n",
    "\n",
    "**Log Torch Tensors as images**  \n",
    "You can log PyTorch Tensors (2d or 3d) directly from the memory, and have them visualized as an image. For more about logging torch tensor see [what you can log and display](https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#pytorch-tensor)\n",
    "and [field types](https://docs.neptune.ai/api-reference/field-types#fileseries) to understand how to upload multiple files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from neptune.types import File\n",
    "\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "dataiter = iter(validloader)\n",
    "images, labels = next(dataiter)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "n_samples = 50\n",
    "img = images[:n_samples]\n",
    "probs = F.softmax(model(img), dim=1)\n",
    "probs = probs.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode probs and Log images tensors  \n",
    "Log Series of Tensors as Image and Predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ps in enumerate(probs):\n",
    "    pred = classes[np.argmax(ps)]\n",
    "    gt = classes[labels[i]]\n",
    "    description = \"\\n\".join([f\"class {classes[n]}: {round(p * 100, 2)}%\" for n, p in enumerate(ps)])\n",
    "\n",
    "    run[\"images/predictions\"].append(\n",
    "        File.as_image(img[i].squeeze().permute(2, 1, 0).clip(0, 1)),\n",
    "        name=f\"{i}_{pred}_{gt}\",\n",
    "        description=description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop run\n",
    "\n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_PyTorch_Support.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
