{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "![Neptune + TensorFlow](https://neptune.ai/wp-content/uploads/2023/09/tensorboard_tensorflow.svg)\n",
    "\n",
    "# Using Neptune with TensorFlow\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/tensorflow/notebooks/Neptune_Tensorflow.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/tensorflow/notebooks/Neptune_Tensorflow.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/tensorflow-support/runs/details?viewId=97f6e558-ba33-4f88-9bc9-0e55347fb79a&detailsTab=dashboard&dashboardId=97f6ac04-2c4b-4d10-97da-cd3a51bbeec8&shortId=TFSUP-101\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/tensorflow/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>\n",
    "\n",
    "In this example, we will use Neptune to log metadata generated from training using TensorFlow.\n",
    "\n",
    "By the end of this guide, you will be able to\n",
    "* Track and version the data.\n",
    "* Log losses and other metrics generated from training.\n",
    "* Log prediction over multiple epochs.\n",
    "* Save the generated model with model registry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U neptune tensorflow numpy requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/tensorflow-support](https://app.neptune.ai/common/tensorflow-support). **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/tensorflow-support\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata to Neptune\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\")\n",
    "with open(\"mnist.npz\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Track and version data files used for training\n",
    "run[\"datasets/version\"].track_files(\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"mnist.npz\") as data:\n",
    "    train_examples = data[\"x_train\"]\n",
    "    train_labels = data[\"y_train\"]\n",
    "    test_examples = data[\"x_test\"]\n",
    "    test_labels = data[\"y_test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"shuffle_buffer_size\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 10,\n",
    "    \"num_visualization_examples\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Log training parameters\n",
    "run[\"training/model/params\"] = params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "train_examples = normalize_img(train_examples)\n",
    "test_examples = normalize_img(test_examples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(params[\"shuffle_buffer_size\"]).batch(params[\"batch_size\"])\n",
    "test_dataset = test_dataset.batch(params[\"batch_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as s:\n",
    "    model.summary(print_fn=lambda x: s.write(x + \"\\n\"))\n",
    "    model_summary = s.getvalue()\n",
    "\n",
    "# (Neptune) Log model summary\n",
    "run[\"training/model/summary\"] = model_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_preds(model, x, y, training):\n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_), y_\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value, _ = loss_and_preds(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params[\"num_epochs\"]):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    for x, y in train_dataset:\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "    # (Neptune) Log metrics for the epoch\n",
    "    # Train metrics\n",
    "    run[\"training/train/loss\"].append(epoch_loss_avg.result())\n",
    "    run[\"training/train/accuracy\"].append(epoch_accuracy.result())\n",
    "\n",
    "    # (Neptune) Log test metrics\n",
    "    test_loss, test_preds = loss_and_preds(model, test_examples, test_labels, False)\n",
    "    run[\"training/test/loss\"].append(test_loss)\n",
    "    acc = epoch_accuracy(test_labels, test_preds)\n",
    "    run[\"training/test/accuracy\"].append(acc)\n",
    "\n",
    "    # (Neptune) Log test prediction\n",
    "    for idx in range(params[\"num_visualization_examples\"]):\n",
    "        np_image = test_examples[idx].numpy().reshape(28, 28)\n",
    "        image = neptune.types.File.as_image(np_image)\n",
    "        pred_label = test_preds[idx].numpy().argmax()\n",
    "        true_label = test_labels[idx]\n",
    "        run[f\"training/visualization/epoch_{epoch}\"].append(\n",
    "            image, description=f\"pred={pred_label} | actual={true_label}\"\n",
    "        )\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == (params[\"num_epochs\"] - 1):\n",
    "        print(\n",
    "            \"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(\n",
    "                epoch, epoch_loss_avg.result(), epoch_accuracy.result()\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking model with Neptune model registry\n",
    "\n",
    "Refer to the [documentation](https://neptune.ai/product/model-registry) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Create a model_version object\n",
    "model_version = neptune.init_model_version(\n",
    "    model=\"TFSUP-TFMOD\",\n",
    "    project=\"common/tensorflow-support\",\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Log metadata to model version\n",
    "model_version[\"run_id\"] = run[\"sys/id\"].fetch()\n",
    "model_version[\"metrics/test_loss\"] = test_loss\n",
    "model_version[\"metrics/test_accuracy\"] = acc\n",
    "model_version[\"datasets/version\"].track_files(\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model artifacts to \"weights\" folder\n",
    "model.save(\"weights\")\n",
    "\n",
    "# (Neptune) Log model artifacts\n",
    "model_version[\"model/weights\"].upload_files(\"weights/*\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()\n",
    "model_version.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/common/tensorflow-support/e/TFSUP-101) and the corresponding [model version](https://app.neptune.ai/common/tensorflow-support/m/TFSUP-TFMOD/v/TFSUP-TFMOD-112/metadata)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FUaDrmRu-h3k",
    "mRhOAcS0Q7Mm",
    "ppUBwlu2V1CS",
    "had9MNRtQ7Mr"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
