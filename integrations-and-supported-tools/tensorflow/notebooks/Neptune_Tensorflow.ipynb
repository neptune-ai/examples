{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "# Using Neptune with TensorFlow\n",
    "\n",
    "In this example, we will use Neptune to log metadata generated from training using TensorFlow.\n",
    "\n",
    "By the end of this guide, you will be able to\n",
    "* Track and version the data.\n",
    "* Log losses and other metrics generated from training.\n",
    "* Log prediction over multiple epochs.\n",
    "* Save the generated model with model registry.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/common/tensorflow-support/e/TFSUP-101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "* If you're running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example logged to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U neptune-client tensorflow numpy requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To connect your script to Neptune and create a new run, we tell Neptune:\n",
    "* **Who you are** - with a Neptune API token\n",
    "* **Where to send your data** - to a Neptune project\n",
    "\n",
    "The cell below lets you record data to the public project [common/tensorflow-support](https://app.neptune.ai/common/tensorflow-support) as an anonymous user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/tensorflow-support\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "Alternatively, you can log the example to your own workspace.\n",
    "\n",
    "To do that, replace the code above with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    project=\"workspace-name/project-name\",  # replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "For example, if your workspace name is `ml-team` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "---\n",
    "\n",
    "You now have new run in Neptune! From here on, we'll use the `run` object to log metadata.\n",
    "\n",
    "**To open the run in Neptune, follow the link that appeared in the cell output.**\n",
    "\n",
    "There's not much to display yet, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata to Neptune\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\"\n",
    ")\n",
    "with open(\"mnist.npz\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Track and version data files used for training\n",
    "run[\"datasets/version\"].track_files(\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"mnist.npz\") as data:\n",
    "    train_examples = data[\"x_train\"]\n",
    "    train_labels = data[\"y_train\"]\n",
    "    test_examples = data[\"x_test\"]\n",
    "    test_labels = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"shuffle_buffer_size\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 10,\n",
    "    \"num_visualization_examples\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Log training parameters\n",
    "run[\"training/model/params\"] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "train_examples = normalize_img(train_examples)\n",
    "test_examples = normalize_img(test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(params[\"shuffle_buffer_size\"]).batch(\n",
    "    params[\"batch_size\"]\n",
    ")\n",
    "test_dataset = test_dataset.batch(params[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as s:\n",
    "    model.summary(print_fn=lambda x: s.write(x + \"\\n\"))\n",
    "    model_summary = s.getvalue()\n",
    "\n",
    "# (Neptune) Log model summary\n",
    "run[\"training/model/summary\"] = model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_preds(model, x, y, training):\n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_), y_\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value, _ = loss_and_preds(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params[\"num_epochs\"]):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    for x, y in train_dataset:\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "    # (Neptune) Log metrics for the epoch\n",
    "    # Train metrics\n",
    "    run[\"training/train/loss\"].log(epoch_loss_avg.result())\n",
    "    run[\"training/train/accuracy\"].log(epoch_accuracy.result())\n",
    "\n",
    "    # (Neptune) Log test metrics\n",
    "    test_loss, test_preds = loss_and_preds(model, test_examples, test_labels, False)\n",
    "    run[\"training/test/loss\"].log(test_loss)\n",
    "    acc = epoch_accuracy(test_labels, test_preds)\n",
    "    run[\"training/test/accuracy\"].log(acc)\n",
    "\n",
    "    # (Neptune) Log test prediction\n",
    "    for idx in range(params[\"num_visualization_examples\"]):\n",
    "        np_image = test_examples[idx].numpy().reshape(28, 28)\n",
    "        image = neptune.types.File.as_image(np_image)\n",
    "        pred_label = test_preds[idx].numpy().argmax()\n",
    "        true_label = test_labels[idx]\n",
    "        run[f\"training/visualization/epoch_{epoch}\"].log(\n",
    "            image, description=f\"pred={pred_label} | actual={true_label}\"\n",
    "        )\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == (params[\"num_epochs\"] - 1):\n",
    "        print(\n",
    "            \"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(\n",
    "                epoch, epoch_loss_avg.result(), epoch_accuracy.result()\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking model with Neptune model registry\n",
    "\n",
    "Refer to the [documentation](https://neptune.ai/product/model-registry) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Create a model_version object\n",
    "model_version = neptune.init_model_version(\n",
    "    model=\"TFSUP-TFMOD\",\n",
    "    project=\"common/tensorflow-support\",\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Neptune) Log metadata to model version\n",
    "model_version[\"run_id\"] = run[\"sys/id\"]\n",
    "model_version[\"metrics/test_loss\"] = test_loss\n",
    "model_version[\"metrics/test_accuracy\"] = acc\n",
    "model_version[\"datasets/version\"].track_files(\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model artifacts to \"weights\" folder\n",
    "model.save(\"weights\")\n",
    "\n",
    "# (Neptune) Log model artifacts\n",
    "model_version[\"model/weights\"].upload_files(\"weights/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()\n",
    "model_version.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/common/tensorflow-support/e/TFSUP-101) and the corresponding [model version](https://app.neptune.ai/common/tensorflow-support/m/TFSUP-TFMOD/v/TFSUP-TFMOD-112/metadata)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FUaDrmRu-h3k",
    "mRhOAcS0Q7Mm",
    "ppUBwlu2V1CS",
    "had9MNRtQ7Mr"
   ],
   "provenance": []
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
