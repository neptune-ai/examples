{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "# Using Neptune with Tensorflow\n",
    "\n",
    "In this example, we will use Neptune to log meta-data generated from training using Tensorflow.\n",
    "\n",
    "By the end of this guide, you will be able to\n",
    "* Track and version the data.\n",
    "* Log losses and other metrics generated from training.\n",
    "* Log prediction over multiple epochs.\n",
    "* Save the generated model with model registry.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=6777136b-938e-4639-943d-3f6bc52f8497)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "* If you're running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example logged to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install neptune-client tensorflow==2.9.2 numpy==1.21.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To connect your script to Neptune and create a new run, we tell Neptune:\n",
    "* **Who you are** - with a Neptune API token\n",
    "* **Where to send your data** - to a Neptune project\n",
    "\n",
    "The cell below lets you record data to the public project [common/quickstarts](https://app.neptune.ai/common/quickstarts) as an anonymous user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/quickstarts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "Alternatively, you can log the example to your own workspace.\n",
    "\n",
    "To do that, replace the code above with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    project=\"workspace-name/project-name\",  # replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "For example, if your workspace name is `ml-team` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "---\n",
    "\n",
    "You now have new run in Neptune! From here on, we'll use the `run` object to log metadata.\n",
    "\n",
    "**To open the run in Neptune, follow the link that appeared in the cell output.**\n",
    "\n",
    "There's not much to display yet, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata to Neptune\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Neptune) Track and version data files used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run['data/details'].track_files('mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('mnist.npz') as data:\n",
    "  train_examples = data['x_train']\n",
    "  train_labels = data['y_train']\n",
    "  test_examples = data['x_test']\n",
    "  test_labels = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "train_examples = normalize_img(train_examples)\n",
    "test_examples = normalize_img(test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(params['shuffle_buffer_size']).batch(params['batch_size'])\n",
    "test_dataset = test_dataset.batch(params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1024,\n",
    "          'shuffle_buffer_size': 100,\n",
    "          'lr': 0.001,\n",
    "          'num_epochs': 10,\n",
    "          'num_visualization_examples': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Neptune) Log training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run['training/model/params'] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer=tf.keras.optimizers.Adam(params['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Neptune) Log model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as s: \n",
    "  model.summary(print_fn=lambda x: s.write(x + '\\n'))\n",
    "  model_summary = s.getvalue()\n",
    "\n",
    "run['training/model/summary'] = model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_preds(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = model(x, training=training)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_), y_\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value, _ = loss_and_preds(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params['num_epochs']):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  for x, y in train_dataset:\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    epoch_loss_avg.update_state(loss_value)\n",
    "    epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "  # (neptune) Log metrics for the epoch\n",
    "  # Train metrics\n",
    "  run['training/train/loss'].log(epoch_loss_avg.result())\n",
    "  run['training/train/accuracy'].log(epoch_accuracy.result())\n",
    "\n",
    "  # (neptune) Log test metrics\n",
    "  test_loss, test_preds = loss_and_preds(model, test_examples, test_labels, False)\n",
    "  run['training/test/loss'].log(test_loss)\n",
    "  acc = epoch_accuracy(test_labels, test_preds)\n",
    "  run['training/test/accuracy'].log(acc)\n",
    "\n",
    "  # (neptune) Log test prediction\n",
    "  for idx in range(params['num_visualization_examples']):\n",
    "    np_image = test_examples[idx].numpy().reshape(28, 28)\n",
    "    image = neptune.types.File.as_image(np_image)\n",
    "    pred_label = test_preds[idx].numpy().argmax()\n",
    "    true_label = test_labels[idx]\n",
    "    run[f'training/visualization/epoch_{epoch}'].log(image, description=f'pred={pred_label} | actual={true_label}')\n",
    "\n",
    "\n",
    "  if epoch % 5 == 0 or epoch == (params['num_epochs'] - 1):\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Explore the results in Neptune\n",
    "\n",
    "<font color=red>[Add steps to view the results in the app.]</font>\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/o/common/org/showroom/e/SHOW-37/charts). <font color=red>[Edit link]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary <font color=red>(optional)</font>\n",
    "\n",
    "<font color=red>[If the example is long, a summary of what was learned.]</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "# Next steps\n",
    "<font color=red>[Tips and next steps. Related links.]</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FUaDrmRu-h3k",
    "mRhOAcS0Q7Mm",
    "ppUBwlu2V1CS",
    "had9MNRtQ7Mr"
   ],
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
