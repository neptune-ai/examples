{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + Sacred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Initialize Neptune and create a `run`,\n",
    "* Log Sacred experiment metrics and atrifacts using `NeptuneObserver()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U neptune-client[sacred] sacred torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neptune.new.integrations.sacred import NeptuneObserver\n",
    "from sacred import Experiment\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.device(\"cuda:0\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a run\n",
    "\n",
    "To connect your script to Neptune and create a new run, we tell Neptune:\n",
    "* **Who you are** - with a Neptune API token\n",
    "* **Where to send your data** - to a Neptune project\n",
    "\n",
    "The cell below lets you record data to the public project [common/sacred-integration](https://app.neptune.ai/o/common/org/sacred-integration) as an anonymous user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run = neptune.init_run(\n",
    "    project=\"common/sacred-integration\", api_token=neptune.ANONYMOUS_API_TOKEN, tags=\"notebook\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can log the example to your own workspace.\n",
    "\n",
    "To do that, replace the code above with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "neptune_run = neptune.init_run(\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    project=\"workspace-name/project-name\",  # replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "For example, if your workspace name is `ml-team` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add NeptuneObserver() to your sacred experiment's observers\n",
    "Dashboard: [https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-11/dashboard/Sacred-Dashboard-6741ab33-825c-4b25-8ebb-bb95c11ca3f4](https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-11/dashboard/Sacred-Dashboard-6741ab33-825c-4b25-8ebb-bb95c11ca3f4)\n",
    "\n",
    "By using NeptuneObserver(), the following is automatically logged to the Neptune app for you:\n",
    "- Hyperparameters\n",
    "- Loss\n",
    "- Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment(\"image_classification\", interactive=True)\n",
    "ex.observers.append(NeptuneObserver(run=neptune_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz=32 * 32 * 3, n_classes=10):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.lin = nn.Linear(input_sz, n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your configuration/hyperparamenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def cfg():\n",
    "    data_dir = \"data/CIFAR10\"\n",
    "    data_tfms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "    lr = 1e-2\n",
    "    bs = 128\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def run(data_dir, data_tfms, lr, bs, device, _run):\n",
    "    trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for i, (x, y) in enumerate(trainloader, 0):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "        # Log loss\n",
    "        ex.log_scalar(\"training/batch/loss\", loss)\n",
    "        # Log accuracy\n",
    "        ex.log_scalar(\"training/batch/acc\", acc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return {\"final_loss\": loss.item(), \"final_acc\": acc.cpu().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your experiment and explore metadata in the Neptune app\n",
    "\n",
    "All metadata is logged automatically to Neptune. \n",
    "\n",
    "After running your script or notebook cell you will get a link similar to:\n",
    "https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-1\n",
    "with common/sacred-integration replaced by your project, and SAC-1 replaced by your run.\n",
    "\n",
    "Click on the link to open the run in Neptune and watch your model training live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Artifacts\n",
    "\n",
    "Model architecture and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = \"model\"\n",
    "print(f\"Saving model archictecture as {model_fname}.txt\")\n",
    "with open(f\"{model_fname}_arch.txt\", \"w\") as f:\n",
    "    f.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model weights as {model_fname}.pth\")\n",
    "torch.save(model.state_dict(), f\"./{model_fname}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.add_artifact(filename=f\"./{model_fname}_arch.txt\", name=f\"{model_fname}_arch\")\n",
    "ex.add_artifact(filename=f\"./{model_fname}.pth\", name=model_fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_Sacred.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
