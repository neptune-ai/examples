{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + Sacred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Initialize Neptune and create a `run`,\n",
    "* Log Sacred experiment metrics and atrifacts using `NeptuneObserver()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install neptune-client[sacred] sacred==0.8.2 torch==1.9.0 torchvision==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neptune.new.integrations.sacred import NeptuneObserver\n",
    "from sacred import Experiment\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.device(\"cuda:0\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Neptune run\n",
    "\n",
    "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
    "\n",
    "To make this example easy to follow, we have created a public project **'common/sacred-integration'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
    "\n",
    "**(Optional)** To log to your Neptune project:\n",
    "\n",
    "* [Create a Neptune account](https://app.neptune.ai/register/)\n",
    "\n",
    "* [Find your API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "* [Find your project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "\n",
    "Pass your credentials to project and api_token arguments of neptune.init()\n",
    "\n",
    "`run = neptune.init(api_token=\"YOUR_API_TOKEN\", project=\"YOUR_WORKSPACE/YOUR_PROJECT\")` # pass your credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run = neptune.init(\n",
    "    project=\"common/sacred-integration\", api_token=\"ANONYMOUS\", tags=\"notebook\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add NeptuneObserver() to your sacred experiment's observers\n",
    "Dashboard: [https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-11/dashboard/Sacred-Dashboard-6741ab33-825c-4b25-8ebb-bb95c11ca3f4](https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-11/dashboard/Sacred-Dashboard-6741ab33-825c-4b25-8ebb-bb95c11ca3f4)\n",
    "\n",
    "By using NeptuneObserver(), the following is automatically logged to the Neptune app for you:\n",
    "- Hyperparameters\n",
    "- Loss\n",
    "- Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment(\"image_classification\", interactive=True)\n",
    "ex.observers.append(NeptuneObserver(run=neptune_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz=32 * 32 * 3, n_classes=10):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.lin = nn.Linear(input_sz, n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your configuration/hyperparamenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def cfg():\n",
    "    data_dir = \"data/CIFAR10\"\n",
    "    data_tfms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "    lr = 1e-2\n",
    "    bs = 128\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def run(data_dir, data_tfms, lr, bs, device, _run):\n",
    "    trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for i, (x, y) in enumerate(trainloader, 0):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "        # Log loss\n",
    "        ex.log_scalar(\"training/batch/loss\", loss)\n",
    "        # Log accuracy\n",
    "        ex.log_scalar(\"training/batch/acc\", acc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return {\"final_loss\": loss.item(), \"final_acc\": acc.cpu().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your experiment and explore metadata in the Neptune app\n",
    "\n",
    "All metadata is logged automatically to Neptune. \n",
    "\n",
    "After running your script or notebook cell you will get a link similar to:\n",
    "https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-1\n",
    "with common/sacred-integration replaced by your project, and SAC-1 replaced by your run.\n",
    "\n",
    "Click on the link to open the run in Neptune and watch your model training live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Artifacts\n",
    "\n",
    "Model architecture and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = \"model\"\n",
    "print(f\"Saving model archictecture as {model_fname}.txt\")\n",
    "with open(f\"{model_fname}_arch.txt\", \"w\") as f:\n",
    "    f.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model weights as {model_fname}.pth\")\n",
    "torch.save(model.state_dict(), f\"./{model_fname}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.add_artifact(filename=f\"./{model_fname}_arch.txt\", name=model_fname + \"_arch\")\n",
    "ex.add_artifact(filename=f\"./{model_fname}.pth\", name=model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_Sacred.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
