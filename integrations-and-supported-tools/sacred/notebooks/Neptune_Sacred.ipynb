{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neptune + Sacred](https://neptune.ai/wp-content/uploads/2023/09/sacred.svg)\n",
    "\n",
    "# Neptune + Sacred\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/sacred/notebooks/Neptune_Sacred.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/sacred/notebooks/Neptune_Sacred.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/sacred-integration/runs/details?viewId=standard-view&detailsTab=dashboard&dashboardId=Sacred-Dashboard-6741ab33-825c-4b25-8ebb-bb95c11ca3f4&shortId=SAC-11\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/sacred/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Initialize Neptune and create a `run`,\n",
    "* Log Sacred experiment metrics and atrifacts using `NeptuneObserver()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U neptune[sacred] sacred torch torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neptune.integrations.sacred import NeptuneObserver\n",
    "from sacred import Experiment\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.device(\"cuda:0\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a run\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/sacred-integration](https://app.neptune.ai/o/common/org/sacred-integration). **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    tags=\"notebook\",\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run = neptune.init_run(\n",
    "    project=\"common/sacred-integration\", api_token=neptune.ANONYMOUS_API_TOKEN, tags=\"notebook\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add NeptuneObserver() to your sacred experiment's observers\n",
    "\n",
    "By using NeptuneObserver(), the following is automatically logged to the Neptune app for you:\n",
    "- Hyperparameters\n",
    "- Loss\n",
    "- Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment(\"image_classification\", interactive=True)\n",
    "ex.observers.append(NeptuneObserver(run=neptune_run))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz=32 * 32 * 3, n_classes=10):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.lin = nn.Linear(input_sz, n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your configuration/hyperparamenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def cfg():\n",
    "    data_dir = \"data/CIFAR10\"\n",
    "    data_tfms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "    lr = 1e-2\n",
    "    bs = 128\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def run(data_dir, data_tfms, lr, bs, device, _run):\n",
    "    trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=0)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for i, (x, y) in enumerate(trainloader, 0):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "        # Log loss\n",
    "        ex.log_scalar(\"training/batch/loss\", loss)\n",
    "        # Log accuracy\n",
    "        ex.log_scalar(\"training/batch/acc\", acc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return {\"final_loss\": loss.item(), \"final_acc\": acc.cpu().item()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your experiment and explore metadata in the Neptune app\n",
    "\n",
    "All metadata is logged automatically to Neptune. \n",
    "\n",
    "After running your script or notebook cell you will get a link similar to:\n",
    "https://app.neptune.ai/o/common/org/sacred-integration/e/SAC-11\n",
    "with common/sacred-integration replaced by your project, and SAC-1 replaced by your run.\n",
    "\n",
    "Click on the link to open the run in Neptune and watch your model training live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Artifacts\n",
    "\n",
    "Model architecture and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = \"model\"\n",
    "print(f\"Saving model archictecture as {model_fname}.txt\")\n",
    "with open(f\"{model_fname}_arch.txt\", \"w\") as f:\n",
    "    f.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model weights as {model_fname}.pth\")\n",
    "torch.save(model.state_dict(), f\"./{model_fname}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.add_artifact(filename=f\"./{model_fname}_arch.txt\", name=f\"{model_fname}_arch\")\n",
    "ex.add_artifact(filename=f\"./{model_fname}.pth\", name=model_fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze logged metadata in the Neptune app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the run link and explore the metadata that were logged to the run in Neptune.\n",
    "\n",
    "Link should look like this: https://app.neptune.ai/o/common/org/sacred-integration/runs/details?viewId=standard-view&detailsTab=metadata&shortId=SAC-11"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_Sacred.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
