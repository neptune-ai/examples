{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EYNlatILeluO"
   },
   "source": [
    "![Neptune + PyTorch Ignite](https://neptune.ai/wp-content/uploads/2023/09/ignite.svg)\n",
    "\n",
    "# Neptune + PyTorch Ignite\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/integrations-and-supported-tools/pytorch-ignite/notebooks/Neptune_PyTorch_Ignite.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/integrations-and-supported-tools/pytorch-ignite/notebooks/Neptune_PyTorch_Ignite.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://app.neptune.ai/o/neptune-ai/org/pytorch-ignite-integration/e/PYTOR-30/charts\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://docs.neptune.ai/integrations/ignite/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zY6B8JTKeluQ",
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Create a `NeptuneLogger()`,\n",
    "* Log training metrics to Neptune using `NeptuneLogger()`,\n",
    "* Upload model checkpoints to Neptune using `NeptuneSaver()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EiPydbIreluR"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NTVvWzR-eluS"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7S4oP2QneluT",
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -U neptune pytorch-ignite scikit-plot torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pgt9N-NneluU"
   },
   "source": [
    "**Note**: If running on Google Colab, restart the kernel and continue execution from the next cell to avoid a `ContextualVersionConflict` error.\n",
    "\n",
    "This error is caused by Colab coming with `future==0.16.0` preinstalled, while `torchvision` updates this to a newer version."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I9FI9oaqeluU",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CrsGX17eluV",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.utils import setup_logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1y70xxTmeluW",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RZl3acXeluY",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"train_batch_size\": 64,\n",
    "    \"val_batch_size\": 64,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.5,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fXCqwaqmelua"
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJV2W6lZeluc"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui44iiKrelue"
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)  # Move model before creating optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vcWRgu2Feluf",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Define DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaBZEKY4eluf",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        MNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
    "        batch_size=val_batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t04ULWGelug"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_data_loaders(params[\"train_batch_size\"], params[\"val_batch_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V-DceXNselug"
   },
   "source": [
    "## Create optimizer, trainer, and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lL3OBjbqeluh"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=params[\"lr\"], momentum=params[\"momentum\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FtveI27Yelui",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## (Neptune) Create NeptuneLogger()\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in a public project. **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "from ignite.contrib.handlers.neptune_logger import NeptuneLogger\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9X4eCjGelui"
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "from ignite.contrib.handlers.neptune_logger import NeptuneLogger\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/pytorch-ignite-integration\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9x-KVoHJeluj"
   },
   "source": [
    "**To open the run, click the Neptune link that appears in the console output.**\n",
    "\n",
    "This will be updated live once training starts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hu1pkNFQeluj"
   },
   "source": [
    "## (Neptune) Attach logger to the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Dy0htR0eluk"
   },
   "outputs": [],
   "source": [
    "trainer.logger = setup_logger(\"Trainer\")\n",
    "\n",
    "neptune_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"batchloss\": loss},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "o4hrvDrheluk"
   },
   "source": [
    "## Create evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5SPE_e-eluk"
   },
   "outputs": [],
   "source": [
    "metrics = {\"accuracy\": Accuracy(), \"loss\": Loss(criterion)}\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "\n",
    "validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzw-MQcrelul"
   },
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_metrics(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    validation_evaluator.run(val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8wiMykjielul"
   },
   "source": [
    "## (Neptune) Attach logger to training and validation evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8LJIYHRelul"
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers.neptune_logger import global_step_from_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXXD55yVelum"
   },
   "outputs": [],
   "source": [
    "train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "\n",
    "neptune_logger.attach_output_handler(\n",
    "    train_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,  # logging at the end of each epoch\n",
    "    tag=\"training\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(\n",
    "        trainer\n",
    "    ),  # takes the epoch of the trainer instead of train_evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRJKcQeHelum"
   },
   "outputs": [],
   "source": [
    "validation_evaluator.logger = setup_logger(\"Validation Evaluator\")\n",
    "\n",
    "neptune_logger.attach_output_handler(\n",
    "    validation_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(\n",
    "        trainer\n",
    "    ),  # takes the epoch of the trainer instead of train_evaluator\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Erd4Xi3Gelun"
   },
   "source": [
    "## (Neptune) Log optimizer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlYJPi3jelun"
   },
   "outputs": [],
   "source": [
    "neptune_logger.attach_opt_params_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fMVUNWmhelun"
   },
   "source": [
    "## (Neptune) Log model's normalized weights and gradients after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9p9HsQoeluo"
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers.neptune_logger import WeightsScalarHandler\n",
    "\n",
    "neptune_logger.attach(\n",
    "    trainer,\n",
    "    log_handler=WeightsScalarHandler(model, reduction=torch.norm),\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BGG8Wi-elup"
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers.neptune_logger import GradsScalarHandler\n",
    "\n",
    "neptune_logger.attach(\n",
    "    trainer,\n",
    "    log_handler=GradsScalarHandler(model, reduction=torch.norm),\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zc-OyA5pelup"
   },
   "source": [
    "## (Neptune) Save model checkpoints\n",
    "__Note:__ `NeptuneSaver` currently does not work on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r38cOqM5elup"
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import Checkpoint\n",
    "from ignite.contrib.handlers.neptune_logger import NeptuneSaver\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    return engine.state.metrics[\"accuracy\"]\n",
    "\n",
    "\n",
    "to_save = {\"model\": model}\n",
    "\n",
    "handler = Checkpoint(\n",
    "    to_save=to_save,\n",
    "    save_handler=NeptuneSaver(neptune_logger),\n",
    "    n_saved=2,\n",
    "    filename_prefix=\"best\",\n",
    "    score_function=score_function,\n",
    "    score_name=\"validation_accuracy\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "# validation_evaluator.add_event_handler(Events.COMPLETED, handler) # Uncomment to save model checkpoints on MacOS/Linux"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TfYH1TaKeluq"
   },
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M91ng_fmeluq"
   },
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=params[\"epochs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0tbeA_z9eluq"
   },
   "source": [
    "Head back to the run on Neptune to watch it being updated live!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SYobp2q4eluq"
   },
   "source": [
    "## (Neptune) Logging additional metadata after training\n",
    "You can access the Neptune run through the `.experiment` attribute of the `NeptuneLogger` object."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I_95r5cqelur"
   },
   "source": [
    "### (Neptune) Log hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NF60rSd8elur"
   },
   "outputs": [],
   "source": [
    "neptune_logger.experiment[\"params\"] = params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vajObO2_elur"
   },
   "source": [
    "### (Neptune) Upload trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FcYJnrJelur"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "neptune_logger.experiment[\"trained_model\"].upload(\"model.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzeOKoxelur"
   },
   "source": [
    "## (Neptune) Stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVbvAyRLelut"
   },
   "outputs": [],
   "source": [
    "neptune_logger.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HIL4YStSelut",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Analyze logged metadata in the Neptune app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IolGWegcelut",
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Go to the run link and explore metadata (metrics, params, model checkpoints) that were logged to the run in Neptune."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
