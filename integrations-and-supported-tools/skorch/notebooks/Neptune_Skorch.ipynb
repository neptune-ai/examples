{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + Skorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "By the end of this guide you will learn how to:\n",
    "\n",
    "* Create a `NeptuneLogger()`,\n",
    "* Log training metrics to Neptune using `NeptuneLogger()`.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/skorch-integration/e/SKOR-13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install neptune-client>=0.11.0 neptune-skorch torch==1.13.0 scikit-learn==1.1.3 skorch==0.12.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune.new as neptune\n",
    "from neptune.new.types import File\n",
    "from skorch.callbacks import NeptuneLogger, Checkpoint\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Using scikit-learn's ```fetch_openml``` to load MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False, cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
    "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a selection of training images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a neural network with PyTorch\n",
    "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dim = X.shape[1]\n",
    "hidden_dim = int(mnist_dim/8)\n",
    "output_dim = len(np.unique(mnist.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dim, hidden_dim, output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network in PyTorch's framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=mnist_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Start a run\n",
    "\n",
    "To connect your script to Neptune and create a new run, we tell Neptune:\n",
    "* **Who you are** - with a Neptune API token\n",
    "* **Where to send your data** - to a Neptune project\n",
    "\n",
    "The cell below lets you record data to the public project [common/skorch-integration](https://app.neptune.ai/common/skorch-integration) as an anonymous user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/skorch-integration\",\n",
    "    name=\"skorch-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Alternatively, you can log the example to your own workspace.\n",
    "\n",
    "To do that, replace the code above with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    project=\"workspace-name/project-name\",  # replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "For example, if your workspace name is `common` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You now have new run in Neptune! From here on, we'll use the `run` object to initialise the **NeptuneLogger**.\n",
    "\n",
    "**To open the run in Neptune, follow the link that appeared in the cell output.**\n",
    "\n",
    "There's not much to display yet, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NeptuneLogger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neptune_logger = NeptuneLogger(run, close_after_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dirname = './checkpoints'\n",
    "checkpoint = Checkpoint(dirname=checkpoint_dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a trainer and pass neptune_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    device=device,\n",
    "    callbacks=[neptune_logger, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log model weights\n",
    "You need to have saved these files to disk using the Checkpoint Callback before trying to upload to Neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger.run[\"training/checkpoints\"].upload_files(checkpoint_dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_test)\n",
    "neptune_logger.run[\"training/acc\"] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mask = y_pred != y_test\n",
    "plot_example(X_test[error_mask], y_pred[error_mask])\n",
    "\n",
    "for (x,y_hat, y) in zip(X_test[error_mask], y_pred[error_mask], y_test[error_mask]):\n",
    "    x_reshaped = x.reshape(28, 28)\n",
    "    neptune_logger.run[\"training/test/misclassified_images\"].log(File.as_image(x_reshaped), description=f\"y_pred={y_hat}, y_true={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger.run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Explore the results in Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Follow the link to the run and explore metadata (metrics, hyperparams, model checkpoints) that were logged to the run in Neptune.\n",
    "\n",
    "You can also check out an [example run](https://app.neptune.ai/o/common/org/skorch-integration/e/SKOR-13)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9918a49f0ff3a4018a272fb676756b6b7681877efd7b7e72359fb8b30d06330a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
