{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "# Version datasets in model training runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "You can version datasets, models, and other file objects as Artifacts in Neptune.\n",
    "\n",
    "This guide shows how to:\n",
    "* Keep track of a dataset version in your model training runs with artifacts  \n",
    "* Query the dataset version from previous runs to make sure you are training on the same dataset version\n",
    "* Group your Neptune Runs by the dataset version they were trained on\n",
    "\n",
    "By the end of this guide, you will train a few models making sure that the same dataset was used and see the Runs for this dataset version in the Neptune app. \n",
    "\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=6777136b-938e-4639-943d-3f6bc52f8497)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-grouped-by-dataset-version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "installation"
    ]
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "! pip install neptune-client scikit-learn==0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Prepare a model training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Create a training script where you:\n",
    "* Specify dataset paths for training and testing\n",
    "* Define model parameters\n",
    "* Calculate the score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TRAIN_DATASET_PATH = \"../datasets/tables/train.csv\"\n",
    "TEST_DATASET_PATH = \"../datasets/tables/test.csv\"\n",
    "\n",
    "\n",
    "def train_model(params, train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "\n",
    "    FEATURE_COLUMNS = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "    TARGET_COLUMN = [\"variety\"]\n",
    "    X_train, y_train = train[FEATURE_COLUMNS], train[TARGET_COLUMN]\n",
    "    X_test, y_test = test[FEATURE_COLUMNS], test[TARGET_COLUMN]\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    return rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LFLtV5R5JKT",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Initialize Neptune and create new run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Connect your script to Neptune application and create new run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XMdpj-Se4t0U",
    "outputId": "d66a1df2-ed95-4790-c799-fe7f6a980b39",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(project=\"common/data-versioning\", api_token=\"ANONYMOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Click on the link above to open this run in Neptune.\n",
    "\n",
    "For now, it is empty but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**Few explanations**\n",
    "\n",
    "In the above code You tell Neptune: \n",
    "\n",
    "* **who you are**: your Neptune API token `api_token` \n",
    "* **where you want to send your data**: your Neptune `project`.\n",
    "\n",
    "At this point you have a new run in Neptune. For now on you will use `run` to log metadata to it.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "\n",
    "Instead of logging data to the public project 'common/quickstarts' as an anonymous user 'neptuner' you can log it to your own project.\n",
    "\n",
    "To do that:\n",
    "\n",
    "1. Get your [Neptune API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "2. Pass the token to ``api_token`` argument of ``neptune.init()`` method: ``api_token=YOUR_API_TOKEN``\n",
    "3. Get your [Neptune project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "3. Pass your project to the `project` argument of the `init()` method.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "neptune.init(project=\"YOUR_WORKSPACE/YOUR_PROJECT\", api_token=\"YOUR_API_TOKEN\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Add tracking of the dataset version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Save datasets versions as Neptune artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "You can also version the entire folder where your datasets are by running\n",
    "\n",
    "```python\n",
    "run[\"datasets\"].track_files(DATASET_FOLDER)\n",
    "```\n",
    "\n",
    "Also, people often keep track of datasets at the project level with [Project metadata](https://docs.neptune.ai/api-reference/project).\n",
    "\n",
    "For more information see [Organize and share dataset versions](https://docs.neptune.ai/how-to-guides/data-versioning/organize-and-share-dataset-versions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training and log parameters and metrics to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log parameters to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 5,\n",
    "    \"max_depth\": 2,\n",
    "    \"max_features\": 1,\n",
    "}\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log test score to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the run ID of your model training from Neptune. \n",
    "\n",
    "This will be useful when asserting the same dataset versions on the baseline and new datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_run_id = run[\"sys/id\"].fetch()\n",
    "print(baseline_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging to the current run\n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a version check for the training and testing datasets\n",
    "\n",
    "You can fetch the dataset version hash from the baseline and compare it with the new current version of the dataset.\n",
    "\n",
    "Create a new Neptune run and track the dataset version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run = neptune.init(project=\"common/data-versioning\", api_token=\"ANONYMOUS\")\n",
    "\n",
    "new_run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "new_run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Neptune run object for the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_run = neptune.init(\n",
    "    project=\"common/data-versioning\",\n",
    "    api_token=\"ANONYMOUS\",\n",
    "    run=baseline_run_id,\n",
    "    mode=\"read-only\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the dataset version with the `.fetch_hash()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_run[\"datasets/train\"].fetch_hash()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the current dataset version with the baseline dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.wait()  # force asynchronous logging operations to finish\n",
    "\n",
    "assert baseline_run[\"datasets/train\"].fetch_hash() == new_run[\"datasets/train\"].fetch_hash()\n",
    "assert baseline_run[\"datasets/test\"].fetch_hash() == new_run[\"datasets/test\"].fetch_hash()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training with new parameters\n",
    "\n",
    "Change the parameters and run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 8,\n",
    "    \"max_depth\": 3,\n",
    "    \"max_features\": 2,\n",
    "}\n",
    "new_run[\"parameters\"] = params\n",
    "\n",
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "\n",
    "new_run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging to the current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.stop()\n",
    "baseline_run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## See all model training runs for this dataset version\n",
    "\n",
    "To see all training runs for a particular dataset version:\n",
    "* Go to the `Runs table` in the Neptune app\n",
    "* Click on **+Add column**, type in 'artifacts/train' and click on it to add to the `Runs table`\n",
    "* Add parameters and test score in the same way\n",
    "* See that your model training run improved thanks to better parameters because the dataset version didn't change. \n",
    "\n",
    "You can also [use ** +Group by**](https://docs.neptune.ai/how-to-guides/neptune-ui/groupby) to group by train dataset versions and find the training runs you care about quickly. \n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=6777136b-938e-4639-943d-3f6bc52f8497)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-grouped-by-dataset-version.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neptune-examples)",
   "language": "python",
   "name": "neptune-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
