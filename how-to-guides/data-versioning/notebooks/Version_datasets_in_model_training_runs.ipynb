{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "# Version datasets in model training runs\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/how-to-guides/data-versioning/notebooks/Version_datasets_in_model_training_runs.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/how-to-guides/data-versioning/notebooks/Version_datasets_in_model_training_runs.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/data-versioning/runs/table?viewId=6777136b-938e-4639-943d-3f6bc52f8497&dash=artifacts&compare=IwdgNMQ\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://docs.neptune.ai/tutorials/data_versioning/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "You can version datasets, models, and other file objects as Artifacts in Neptune.\n",
    "\n",
    "This guide shows how to:\n",
    "* Keep track of a dataset version in your model training runs with artifacts  \n",
    "* Query the dataset version from previous runs to make sure you are training on the same dataset version\n",
    "* Group your Neptune Runs by the dataset version they were trained on\n",
    "\n",
    "By the end of this guide, you will train a few models making sure that the same dataset was used and see the Runs for this dataset version in the Neptune app. \n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-grouped-by-dataset-version.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "installation"
    ]
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbRjEopuzLrZ",
    "outputId": "cb6bf505-f63a-4f4e-99a0-1a1acc99216c"
   },
   "outputs": [],
   "source": [
    "! curl https://raw.githubusercontent.com/neptune-ai/examples/main/how-to-guides/data-versioning/datasets/tables/train.csv --create-dirs -o ../datasets/tables/train.csv\n",
    "! curl https://raw.githubusercontent.com/neptune-ai/examples/main/how-to-guides/data-versioning/datasets/tables/test.csv --create-dirs -o ../datasets/tables/test.csv\n",
    "! curl https://raw.githubusercontent.com/neptune-ai/examples/main/how-to-guides/data-versioning/datasets/tables/train_v2.csv --create-dirs -o ../datasets/tables/train_v2.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "! pip install -U neptune scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Prepare a model training script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Create a training script where you:\n",
    "* Specify dataset paths for training and testing\n",
    "* Define model parameters\n",
    "* Calculate the score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TRAIN_DATASET_PATH = \"../datasets/tables/train.csv\"\n",
    "TEST_DATASET_PATH = \"../datasets/tables/test.csv\"\n",
    "\n",
    "\n",
    "def train_model(params, train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "\n",
    "    FEATURE_COLUMNS = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "    TARGET_COLUMN = [\"variety\"]\n",
    "    X_train, y_train = train[FEATURE_COLUMNS], train[TARGET_COLUMN]\n",
    "    X_test, y_test = test[FEATURE_COLUMNS], test[TARGET_COLUMN]\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    return rf.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Initialize Neptune and create new run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in a public project. **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. \n",
    "\n",
    "    To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(project=\"common/data-versioning\", api_token=neptune.ANONYMOUS_API_TOKEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Add tracking of the dataset version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Save datasets versions as Neptune artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "You can also version the entire folder where your datasets are by running\n",
    "\n",
    "```python\n",
    "run[\"datasets\"].track_files(DATASET_FOLDER)\n",
    "```\n",
    "\n",
    "Also, people often keep track of datasets at the project level with [Project metadata](https://docs.neptune.ai/api-reference/project).\n",
    "\n",
    "For more information see [Organize and share dataset versions](https://docs.neptune.ai/how-to-guides/data-versioning/organize-and-share-dataset-versions)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training and log parameters and metrics to Neptune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log parameters to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 5,\n",
    "    \"max_depth\": 2,\n",
    "    \"max_features\": 1,\n",
    "}\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log test score to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the run ID of your model training from Neptune. \n",
    "\n",
    "This will be useful when asserting the same dataset versions on the baseline and new datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_run_id = run[\"sys/id\"].fetch()\n",
    "print(baseline_run_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging to the current run\n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a version check for the training and testing datasets\n",
    "\n",
    "You can fetch the dataset version hash from the baseline and compare it with the new current version of the dataset.\n",
    "\n",
    "Create a new Neptune run and track the dataset version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run = neptune.init_run(project=\"common/data-versioning\", api_token=neptune.ANONYMOUS_API_TOKEN)\n",
    "\n",
    "new_run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "new_run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Neptune run object for the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_run = neptune.init_run(\n",
    "    project=\"common/data-versioning\",\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    with_id=baseline_run_id,\n",
    "    mode=\"read-only\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the dataset version with the `.fetch_hash()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_run[\"datasets/train\"].fetch_hash()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the current dataset version with the baseline dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.wait()  # force asynchronous logging operations to finish\n",
    "\n",
    "assert baseline_run[\"datasets/train\"].fetch_hash() == new_run[\"datasets/train\"].fetch_hash()\n",
    "assert baseline_run[\"datasets/test\"].fetch_hash() == new_run[\"datasets/test\"].fetch_hash()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training with new parameters\n",
    "\n",
    "Change the parameters and run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 8,\n",
    "    \"max_depth\": 3,\n",
    "    \"max_features\": 2,\n",
    "}\n",
    "new_run[\"parameters\"] = params\n",
    "\n",
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "\n",
    "new_run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging to the current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.stop()\n",
    "baseline_run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## See all model training runs for this dataset version\n",
    "\n",
    "To see all training runs for a particular dataset version:\n",
    "* Go to the `Runs table` in the Neptune app\n",
    "* Click on **+Add column**, type in 'artifacts/train' and click on it to add to the `Runs table`\n",
    "* Add parameters and test score in the same way\n",
    "* See that your model training run improved thanks to better parameters because the dataset version didn't change. \n",
    "\n",
    "You can also [use ** +Group by**](https://docs.neptune.ai/how-to-guides/neptune-ui/groupby) to group by train dataset versions and find the training runs you care about quickly. \n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=6777136b-938e-4639-943d-3f6bc52f8497)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-grouped-by-dataset-version.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
