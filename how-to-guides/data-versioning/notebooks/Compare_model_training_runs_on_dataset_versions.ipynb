{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "# Compare model training runs on dataset versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "You can version datasets, models, and other file objects as Artifacts in Neptune.\n",
    "\n",
    "This guide shows how to:\n",
    "* Keep track of the dataset version with Neptune artifacts\n",
    "* See if models were trained on the same dataset version\n",
    "* Compare datasets in the Neptune app to see what changed\n",
    "\n",
    "By the end of this guide, you will train a few models on different dataset versions and compare those versions in the Neptune app.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=2b313653-1aa2-40e8-8bf2-cd13f0f96862&base=DAT-18&to=DAT-17)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-compare-runs-on-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "installation"
    ]
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "! pip install neptune-client scikit-learn==0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Prepare a model training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "As an example, we'll use a script that trains a scikit-learn model on the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TRAIN_DATASET_PATH = \"../datasets/tables/train.csv\"\n",
    "TEST_DATASET_PATH = \"../datasets/tables/test.csv\"\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 5,\n",
    "    \"max_depth\": 1,\n",
    "    \"max_features\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "def train_model(params, train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "\n",
    "    FEATURE_COLUMNS = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "    TARGET_COLUMN = [\"variety\"]\n",
    "    X_train, y_train = train[FEATURE_COLUMNS], train[TARGET_COLUMN]\n",
    "    X_test, y_test = test[FEATURE_COLUMNS], test[TARGET_COLUMN]\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    return rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Initialize Neptune and create new run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Connect your script to Neptune application and create new run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(project=\"common/data-versioning\", api_token=\"ANONYMOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Click on the link above to open this run in Neptune.\n",
    "\n",
    "It's empty at the moment, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**Few explanations**\n",
    "\n",
    "In the above code You tell Neptune: \n",
    "\n",
    "* **who you are**: your Neptune API token `api_token` \n",
    "* **where you want to send your data**: your Neptune `project`.\n",
    "\n",
    "At this point you have a new run in Neptune. For now on you will use `run` to log metadata to it.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "\n",
    "Instead of logging data to the public project `common/data-versioning` as an anonymous user `neptuner`, you can log it to your own project.\n",
    "\n",
    "To do that:\n",
    "\n",
    "1. Get your [Neptune API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "2. Pass the token to ``api_token`` argument of ``neptune.init()`` method: ``api_token=YOUR_API_TOKEN``\n",
    "3. Get your [Neptune project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "3. Pass your project to the `project` argument of the `init()` method.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "neptune.init(project=\"YOUR_WORKSPACE/YOUR_PROJECT\",\n",
    "             api_token=\"YOUR_API_TOKEN\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Add tracking of the dataset version and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Save datasets versions as Neptune artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "You can also version the entire folder where your datasets by running\n",
    "\n",
    "```python\n",
    "run[\"datasets\"].track_files(DATASET_FOLDER)\n",
    "```\n",
    "\n",
    "Also, people often keep track of datasets at the project level with [Project metadata](https://docs.neptune.ai/api-reference/project).\n",
    "\n",
    "For more information see [Organize and share dataset versions](https://docs.neptune.ai/how-to-guides/data-versioning/organize-and-share-dataset-versions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training and log parameters and metrics to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a model and log the test score to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"parameters\"] = params\n",
    "\n",
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "\n",
    "run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging to the current run \n",
    "<font color=red>**Warning:**</font><br>\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change training dataset\n",
    "\n",
    "Let's now change the training dataset that we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"../datasets/tables/train_v2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training on a new training dataset\n",
    "\n",
    "Let's run model training again.\n",
    "* Initialize the Neptune run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run = neptune.init(project=\"common/data-versioning\", api_token=\"ANONYMOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log dataset versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)\n",
    "new_run[\"datasets/test\"].track_files(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Execute model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run[\"parameters\"] = params\n",
    "\n",
    "score = train_model(params, TRAIN_DATASET_PATH, TEST_DATASET_PATH)\n",
    "\n",
    "new_run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop logging to currently active Neptune run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "## Compare model training runs in the Neptune app\n",
    "\n",
    "To see that the score changed due to different dataset version: \n",
    "* Go to the `Runs table` in the Neptune app\n",
    "* Click on **+Add column**, type in 'artifacts/train' and click on it to add to the `Runs table`\n",
    "* Click on the **Eye** icon and go to [Compare runs > Artifacts](https://docs.neptune.ai/you-should-know/comparing-runs#artifact) to see how the datasets changed\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/experiments?compare=IwdgNMQ&split=tbl&dash=artifacts&viewId=2b313653-1aa2-40e8-8bf2-cd13f0f96862&base=DAT-18&to=DAT-17)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/artifacts-compare-runs-on-dataset.png)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
