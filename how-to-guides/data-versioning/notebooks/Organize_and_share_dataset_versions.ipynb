{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "# Organize and share dataset versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "You can log and query metadata at a project level including dataset and model versions, text notes, images, notebook files, and anything else you can log to a single Run.\n",
    "\n",
    "This guide shows how to:\n",
    "* Log versions of all the datasets used in a project\n",
    "* Organize dataset version metadata in the Neptune UI\n",
    "* Share all the currently used dataset versions with your team\n",
    "* Assert that you are training on the latest dataset version available\n",
    "\n",
    "By the end of this guide, you will log various dataset versions, organize them in the Neptune UI and see how to share them with a persistent link.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/data-versioning/metadata?path=datasets%2Ftrain_sampled%2F&attribute=latest&file=train_sampled4.csv&filePath=.)\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/Screenshot-from-2021-12-23-11-46-23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "installation"
    ]
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment",
     "installation"
    ]
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "! pip install neptune-client>=0.14 scikit-learn==0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the Neptune project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to stop your project once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "project = neptune.init_project(name=\"common/data-versioning\", api_token=\"ANONYMOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few explanations**\n",
    "\n",
    "In the above code You tell Neptune: \n",
    "\n",
    "* **who you are**: your Neptune API token `api_token` \n",
    "* **where you want to send your data**: your Neptune `project`.\n",
    "\n",
    "At this point you can log metadata to the Neptune `project`. \n",
    "\n",
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "\n",
    "Instead of logging data to the public project 'common/data-versioning' as an anonymous user 'neptuner' you can log it to your own project.\n",
    "\n",
    "To do that:\n",
    "\n",
    "1. Get your [Neptune API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "2. Pass the token to ``api_token`` argument of ``neptune.init()`` method: ``api_token=YOUR_API_TOKEN``\n",
    "3. Get your [Neptune project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "3. Pass your project to the ``project`` argument of the ``neptune.init_project()``.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "neptune.init_project(name='my_workspace/my_project', \n",
    "                     api_token='MY_API_TOKEN')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Step 2: Log various dataset versions to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Create a few different training data samples and log them as different dataset versions to a Neptune project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MetadataInconsistency",
     "evalue": "Cannot delete datasets. Attribute not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMetadataInconsistency\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128748/3610127474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py_37/lib/python3.7/site-packages/neptune/new/handler.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, path, wait)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Following attributes are implemented only for docstring hints and autocomplete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_37/lib/python3.7/site-packages/neptune/new/attribute_container.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, path, wait)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mverify_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_37/lib/python3.7/site-packages/neptune/new/attribute_container.py\u001b[0m in \u001b[0;36m_pop_impl\u001b[0;34m(self, parsed_path, wait)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menqueue_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeleteAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_37/lib/python3.7/site-packages/neptune/new/internal/run_structure.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_37/lib/python3.7/site-packages/neptune/new/internal/run_structure.py\u001b[0m in \u001b[0;36m_pop_impl\u001b[0;34m(self, ref, sub_path, attr_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             raise MetadataInconsistency(\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;34m\"Cannot delete {}. Attribute not found.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             )\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMetadataInconsistency\u001b[0m: Cannot delete datasets. Attribute not found."
     ]
    }
   ],
   "source": [
    "project['datasets'].pop() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../datasets/tables/train.csv')\n",
    "\n",
    "for i in range(5):\n",
    "    train_sample=train.sample(frac=0.5 + 0.1*i)\n",
    "    train_sample.to_csv('../datasets/tables/train_sampled.csv', index=None)\n",
    "    project[f'datasets/train_sampled/v{i}'].track_files('../datasets/tables/train_sampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can confirm that it was logged by looking at the project metadata structure in the **datasets** namespace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sys': {'creation_time': <neptune.new.attributes.atoms.datetime.Datetime at 0x7f468c5bc850>,\n",
       "  'id': <neptune.new.attributes.atoms.string.String at 0x7f468c5bc450>,\n",
       "  'modification_time': <neptune.new.attributes.atoms.datetime.Datetime at 0x7f4663f02f10>,\n",
       "  'monitoring_time': <neptune.new.attributes.atoms.integer.Integer at 0x7f4663f02590>,\n",
       "  'owner': <neptune.new.attributes.atoms.string.String at 0x7f4663f02690>,\n",
       "  'ping_time': <neptune.new.attributes.atoms.datetime.Datetime at 0x7f4663f02a10>,\n",
       "  'running_time': <neptune.new.attributes.atoms.float.Float at 0x7f4663f02a90>,\n",
       "  'size': <neptune.new.attributes.atoms.float.Float at 0x7f4663f02bd0>,\n",
       "  'state': <neptune.new.attributes.atoms.run_state.RunState at 0x7f4663f02850>},\n",
       " 'datasets': {'train_sampled': {'v0': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f464896f4d0>,\n",
       "   'v1': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663ef9510>,\n",
       "   'v2': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663ef3b50>,\n",
       "   'v3': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663efde10>,\n",
       "   'v4': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f468c549a50>}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.get_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the latest version of a dataset and create a separate dataset version called 'latest'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_latest_version():\n",
    "    artifact_name = project.get_structure()['datasets']['train_sampled'].keys()\n",
    "    versions = [int(version.replace('v','')) for version in artifact_name if version != 'latest']\n",
    "    latest_version = max(versions)\n",
    "    return latest_version\n",
    "\n",
    "latest_version = get_latest_version()\n",
    "latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project['datasets/train_sampled/latest'] = project[f'datasets/train_sampled/v{latest_version}'].fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: See dataset versions in the Neptune UI and share them with the team\n",
    "\n",
    "You can get a list of all datasets used in a project by running ``project.get_structure()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_sampled': {'v0': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f464896f4d0>,\n",
       "  'v1': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663ef9510>,\n",
       "  'v2': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663ef3b50>,\n",
       "  'v3': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f4663efde10>,\n",
       "  'v4': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f468c549a50>,\n",
       "  'latest': <neptune.new.attributes.atoms.artifact.Artifact at 0x7f46491b4210>}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.get_structure()['datasets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You and your team can also see and access all that in the Neptune UI.\n",
    "Go to your project and then **Project Metadata > datasets**\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/Screenshot-from-2021-12-23-11-46-23.png)\n",
    "\n",
    "As all links in the Neptune UI URL of the Project metadata for your project is persistent. \n",
    "\n",
    "For example:\n",
    "\n",
    "https://app.neptune.ai/o/common/org/data-versioning/metadata?path=datasets%2Ftrain_sampled%2F&attribute=latest&file=train_sampled4.csv&filePath=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LFLtV5R5JKT",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Step 4: Create a new Neptune Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Connect your script to Neptune application and create new run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XMdpj-Se4t0U",
    "outputId": "d66a1df2-ed95-4790-c799-fe7f6a980b39",
    "tags": [
     "code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/common/data-versioning/e/DAT-63\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(project='common/data-versioning', api_token='ANONYMOUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "**Few explanations**\n",
    "\n",
    "In the above code You tell Neptune: \n",
    "\n",
    "* **who you are**: your Neptune API token `api_token` \n",
    "* **where you want to send your data**: your Neptune `project`.\n",
    "\n",
    "At this point you have new Run in Neptune. For now on you will use `run` to log metadata to it.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "\n",
    "Instead of logging data to the public project 'common/quickstarts' as an anonymous user 'neptuner' you can log it to your own project.\n",
    "\n",
    "To do that:\n",
    "\n",
    "1. Get your [Neptune API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
    "2. Pass the token to ``api_token`` argument of ``neptune.init()`` method: ``api_token=YOUR_API_TOKEN``\n",
    "3. Get your [Neptune project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
    "3. Pass your project to the ``project`` argument of the ``neptune.init()``.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "neptune.init(project='my_workspace/my_project', \n",
    "             api_token='MY_API_TOKEN')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Step 5: Assert that you are training on the latest dataset version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "Log dataset version of the dataset you want to train your models on as a Neptune artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = '../datasets/tables/train_sampled.csv'\n",
    "run[\"datasets/train\"].track_files(TRAIN_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert that it is the same dataset as the latest dataset version in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait()\n",
    "project.wait()\n",
    "assert run[\"datasets/train\"].fetch_hash() == project['datasets/train_sampled/latest'].fetch_hash()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "You can also download the latest version of the dataset by running \n",
    "\n",
    "```python\n",
    "project['datasets/train_sampled/latest'].download()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6: Run model training and log parameters and metrics to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a model and log the test score to Neptune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/miniconda3/envs/py_37/lib/python3.7/site-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "TEST_DATASET_PATH = '../datasets/tables/test.csv'\n",
    "\n",
    "PARAMS = {'n_estimators': 8,\n",
    "          'max_depth':3,\n",
    "          'max_features':2,\n",
    "         }\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "test = pd.read_csv(TEST_DATASET_PATH)\n",
    "\n",
    "FEATURE_COLUMNS = ['sepal.length', 'sepal.width', 'petal.length', 'petal.width']\n",
    "TARGET_COLUMN = ['variety']\n",
    "X_train, y_train = train[FEATURE_COLUMNS], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[FEATURE_COLUMNS], test[TARGET_COLUMN]\n",
    "\n",
    "rf = RandomForestClassifier(**PARAMS)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "run[\"metrics/test_score\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop logging to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 3 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 operations synced, thanks for waiting!\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37",
   "language": "python",
   "name": "py_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
