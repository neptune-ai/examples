{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Neptune in HPO training job\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/how-to-guides/neptune-hpo/notebooks/Neptune_hpo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/how-to-guides/neptune-hpo/notebooks/Neptune_hpo.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://app.neptune.ai/o/common/org/showroom/runs/details?viewId=standard-view&detailsTab=charts&shortId=SHOW-27624\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://docs.neptune.ai/tutorials/hpo/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When running a hyperparameter optimization job, you can use Neptune to track all the metadata from the study and each trial.\n",
    "\n",
    "In this guide, you'll learn how to configure Neptune to track the metadata of your hyperparameter optimization job."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U neptune numpy torch torchvision tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import trange\n",
    "from functools import reduce\n",
    "from neptune.utils import stringify_unsupported"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata across HPO trials into a single run\n",
    "\n",
    "Create a global Neptune run to log metadata (i.e. metrics) across different trials.\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in a public project. **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    tags=[\"sweep-level\"],  # to identify a run that contains multiple trials\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://app.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. The workspace name is displayed in the top-left corner of the app. \n",
    "\n",
    "    To copy the project path, in the top-right corner, open the settings menu and select **Properties**.\n",
    "\n",
    "For more help, see [Setting Neptune credentials](https://docs.neptune.ai/setup/setting_credentials) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    project=\"common/pytorch-integration\",\n",
    "    tags=[\"sweep-level\"],  # to identify a run that contains multiple trials\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To open the run in the Neptune web app, click the link that appeared in the cell output.**\n",
    "\n",
    "We'll use the `run` object we just created to log metadata. You'll see the metadata appear in the app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 1,\n",
    "    \"input_size\": (3, 32, 32),\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_size\": 1000,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "input_size = reduce(lambda x, y: x * y, parameters[\"input_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-4, 1e-3, 1e-2]  # learning rate choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, self.input_size)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(\n",
    "    input_size,\n",
    "    input_size,\n",
    "    parameters[\"n_classes\"],\n",
    ").to(parameters[\"device\"])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FakeData(\n",
    "    size=parameters[\"dataset_size\"],\n",
    "    image_size=parameters[\"input_size\"],\n",
    "    num_classes=parameters[\"n_classes\"],\n",
    "    transform=data_tfms[\"train\"],\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=parameters[\"batch_size\"], shuffle=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lr in enumerate(learning_rates):\n",
    "    # Log hyperparameters\n",
    "    run[f\"trials/{i}/parms\"] = stringify_unsupported(parameters)\n",
    "    run[f\"trials/{i}/parms/lr\"] = lr\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for _ in trange(parameters[\"epochs\"]):\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "            # Log metrics\n",
    "            run[f\"trials/{i}/training/batch/loss\"].append(loss)\n",
    "            run[f\"trials/{i}/training/batch/acc\"].append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Stop logging\n",
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata from each HPO trial into separate runs\n",
    "\n",
    "Create local Neptune runs to log metrics from each trial into a separate run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lr in enumerate(learning_rates):\n",
    "    # Create a new run\n",
    "    run = neptune.init_run(\n",
    "        api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "        project=\"common/pytorch-integration\",\n",
    "        name=f\"trial-{i}\",\n",
    "        tags=[\"trial-level\"],  # to indicate that the run only contains results from a single trial\n",
    "    )\n",
    "\n",
    "    # Log hyperparameters\n",
    "    run[\"parms\"] = stringify_unsupported(parameters)\n",
    "    run[\"parms/lr\"] = lr\n",
    "\n",
    "    for _ in trange(parameters[\"epochs\"]):\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "            # Log metrics\n",
    "            run[\"training/batch/loss\"].append(loss)\n",
    "            run[\"training/batch/acc\"].append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Stop logging\n",
    "    run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the results in Neptune\n",
    "Follow the link to the run and explore metadata (such as metrics and hyperparameters) that were logged to the run in Neptune.\n",
    "\n",
    "You can also check out these example runs:\n",
    "- [Log metadata across HPO trials into a single run](https://app.neptune.ai/o/common/org/pytorch-integration/e/PYTOR1-1025/all)\n",
    "- [Log metadata from each HPO trial into separate runs](https://app.neptune.ai/o/common/org/pytorch-integration/experiments?split=tbl&dash=Loss-vs-Accuracy-bf72be6c-d771-457f-8f51-30fef2bee3d5&viewId=97f3180c-a819-4054-99d7-d62dac102450)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
