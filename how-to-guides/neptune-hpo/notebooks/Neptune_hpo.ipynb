{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Neptune in HPO training job\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/how-to-guides/neptune-hpo/notebooks/Neptune_hpo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/how-to-guides/neptune-hpo/notebooks/Neptune_hpo.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://app.neptune.ai/o/showcase/org/hpo/runs/table?viewId=9ca5a860-361e-4b3e-aae8-ddd8c5454cba&detailsTab=dashboard&dash=table&type=run\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://docs-legacy.neptune.ai/tutorials/hpo/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When running a hyperparameter optimization job, you can use Neptune to track all the metadata from the study and each trial.\n",
    "\n",
    "In this guide, you'll learn how to configure Neptune to track the metadata of your hyperparameter optimization job."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs-legacy.neptune.aitune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU neptune numpy torch torchvision tqdm \"numpy<2.0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import trange\n",
    "from functools import reduce\n",
    "from neptune.utils import stringify_unsupported"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 2,\n",
    "    \"input_size\": (3, 32, 32),\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_size\": 1000,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "input_size = reduce(lambda x, y: x * y, parameters[\"input_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1]  # learning rate choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, self.input_size)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(\n",
    "    input_size,\n",
    "    input_size,\n",
    "    parameters[\"n_classes\"],\n",
    ").to(parameters[\"device\"])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FakeData(\n",
    "    size=parameters[\"dataset_size\"],\n",
    "    image_size=parameters[\"input_size\"],\n",
    "    num_classes=parameters[\"n_classes\"],\n",
    "    transform=data_tfms[\"train\"],\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=parameters[\"batch_size\"], shuffle=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata across HPO trials into a single run\n",
    "\n",
    "Create a global Neptune run to log metadata across different trials.\n",
    "\n",
    "To connect to the Neptune app, you need to tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/hpo](https://app.neptune.ai/common/hpo).  \n",
    "\n",
    "**Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "#### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"]=getpass(\"Enter your Neptune API token: \")\n",
    "os.environ[\"NEPTUNE_PROJECT\"]=\"workspace-name/project-name\",  # Replace with your workspace and project names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"] = neptune.ANONYMOUS_API_TOKEN\n",
    "os.environ[\"NEPTUNE_PROJECT\"] = \"common/hpo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(tags=[\"notebook\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To view the newly created run and its metadata in the Neptune app, use the link that appeared in the cell output.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lr in enumerate(learning_rates):\n",
    "    # Log hyperparameters\n",
    "    run[f\"trials/{i}/params\"] = stringify_unsupported(parameters)\n",
    "    run[f\"trials/{i}/params/lr\"] = lr\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize fields for best values across all trials\n",
    "    best_loss = None\n",
    "\n",
    "    for _ in trange(parameters[\"epochs\"]):\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "            # Log trial metrics\n",
    "            run[f\"trials/{i}/metrics/batch/loss\"].append(loss)\n",
    "            run[f\"trials/{i}/metrics/batch/acc\"].append(acc)\n",
    "\n",
    "            # Log best values across all trials\n",
    "            if best_loss is None or loss < best_loss:\n",
    "                run[\"best/trial\"] = i\n",
    "                run[\"best/metrics/loss\"] = best_loss = loss\n",
    "                run[\"best/metrics/acc\"] = acc\n",
    "                run[\"best/params\"] = stringify_unsupported(parameters)\n",
    "                run[\"best/params/lr\"] = lr\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the results in Neptune\n",
    "Follow the link to the run and explore the logged metadata (such as metrics and hyperparameters) in Neptune:\n",
    "\n",
    "- The best trial, with its metrics and parameters, is available in the *best* namespace\n",
    "- Metadata across all trials is available in the *trials* namespace\n",
    "\n",
    "To organize all relevant metadata in one view, create a [custom dashboard](https://docs-legacy.neptune.aitune.ai/app/custom_dashboard/). [See an example](https://app.neptune.ai/o/showcase/org/hpo/runs/details?viewId=9ca5a9f2-e889-435c-a6f4-77cc41886832&detailsTab=dashboard&dashboardId=9ca5aa39-24cd-43bf-8cef-07aae8b4478b&shortId=HPO-1&type=run).\n",
    "\n",
    "You can also create [saved table views](https://docs-legacy.neptune.aitune.ai/app/experiments/#custom-views) to view best trials across different runs. An example is available [here](https://app.neptune.ai/o/showcase/org/hpo/runs/table?viewId=9ca5a9f2-e889-435c-a6f4-77cc41886832&detailsTab=dashboard&dash=table&type=run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metadata from each HPO trial into separate runs\n",
    "\n",
    "You can also log metadata from each trial into separate runs. This way, you can track metadata from each trial separately.  \n",
    "Aggregated values can be logged to a parent sweep-level run. Sweep-level identifiers can be used to group all trials from the same sweep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sweep-level identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "sweep_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize sweep-level run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_run = neptune.init_run(\n",
    "    tags=[\"notebook\", \"sweep-level\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign sweep_id to sweep-level run as a group tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_run[\"sys/group_tags\"].add(sweep_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lr in enumerate(learning_rates):\n",
    "    # Create trial-level run\n",
    "    with neptune.init_run(\n",
    "        name=f\"trial-{i}\",\n",
    "        tags=[\n",
    "            \"notebook\",\n",
    "            \"trial-level\",\n",
    "        ],  # to indicate that the run only contains results from a single trial\n",
    "    ) as trial_run:\n",
    "        # Add sweep_id to the trial-level run\n",
    "        trial_run[\"sys/group_tags\"].add(sweep_id)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        trial_run[\"params\"] = stringify_unsupported(parameters)\n",
    "        trial_run[\"params/lr\"] = lr\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # Initialize fields for best values across all trials\n",
    "        best_loss = None\n",
    "\n",
    "        for _ in trange(parameters[\"epochs\"]):\n",
    "            for x, y in trainloader:\n",
    "                x, y = x.to(parameters[\"device\"]), y.to(parameters[\"device\"])\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model.forward(x)\n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "                # Log trial metrics\n",
    "                trial_run[\"metrics/batch/loss\"].append(loss)\n",
    "                trial_run[\"metrics/batch/acc\"].append(acc)\n",
    "\n",
    "                # Log best values across all trials to sweep-level run\n",
    "                if best_loss is None or loss < best_loss:\n",
    "                    sweep_run[\"best/trial\"] = i\n",
    "                    sweep_run[\"best/metrics/loss\"] = best_loss = loss\n",
    "                    sweep_run[\"best/metrics/acc\"] = acc\n",
    "                    sweep_run[\"best/params\"] = stringify_unsupported(parameters)\n",
    "                    sweep_run[\"best/params/lr\"] = lr\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the sweep-level run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the results in Neptune\n",
    "Follow the link to the runs and explore the logged metadata (such as metrics and hyperparameters) in Neptune:\n",
    "\n",
    "- The best trial, with its metrics and parameters, is available in the *best* namespace of the sweep-level run\n",
    "- Metadata across all trials are available in the trial-level runs\n",
    "\n",
    "To group all trials under a sweep, use the [run groups](https://docs-legacy.neptune.aitune.ai/usage/groups/). [See an example](https://app.neptune.ai/o/showcase/org/hpo/runs/table?viewId=9ca5a860-361e-4b3e-aae8-ddd8c5454cba&detailsTab=dashboard&dash=table&type=run)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
