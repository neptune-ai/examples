{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to present CV with Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THIzFFk81nme"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "When training models with cross-validation, you can use Neptune namespaces to organize, visualize and compare models.\n",
    "\n",
    "By the end of this guide, you will learn how to organize your run to track cross-validation metadata, so that you can easily analyze the results.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/showroom/e/SHOW-3700)\n",
    "\n",
    "[![image](https://files.gitbook.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MT0sYKbymfLAAtTq4-t%2Fuploads%2FLRq4l78xEp31FFS5WzFM%2Fimage.png?alt=media&token=be868c83-7b1b-4314-b138-677531720f0e)](https://app.neptune.ai/o/common/org/showroom/e/SHOW-3700)\n",
    "<center><small>CV results presented in Neptune UI</small></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Make sure that you have:\n",
    "* [Python 3.7+ installed](https://www.python.org/downloads/),\n",
    "* [Basic familiarity with Neptune (create run and log metadata to it)](hhttps://docs.neptune.ai/you-should-know/what-can-you-log-and-display),\n",
    "* Familiarity with cross-validation techniques in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54CFqKRANLK5",
    "outputId": "a19f2835-22ab-41c9-ab13-e6e4d8fdbea9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install neptune-client torch==1.10.2 torchvision==0.11.3 scikit-learn==1.0.2 #add other dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfqmkNLB1SRu"
   },
   "source": [
    "## Step 1: Create a Neptune *Run*\n",
    "\n",
    "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
    "\n",
    "To make this example easy to follow, we have created a public project **'common/showroom'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
    "\n",
    "**(Optional)** If you want to log to your own project you have to have or create [Neptune account](https://app.neptune.ai/register/) and [project](https://docs.neptune.ai/getting-started/installation#setting-the-project-name).\n",
    "Then you can pass [project](https://docs.neptune.ai/getting-started/installation#setting-the-project-name) and [api_token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token) arguments to the `init()` method.\n",
    "\n",
    "`run = neptune.init(api_token='<YOUR_API_TOKEN>', project='<YOUR_WORKSPACE/YOUR_PROJECT>')` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIAK4NasfQ_f",
    "outputId": "219c6e97-2b72-4241-fbe2-aa1200407190"
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"common/showroom\",\n",
    "    api_token=\"ANONYMOUS\",\n",
    "    tags=[\"Colab Notebook\", \"cross-validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4StPQOmmh_d"
   },
   "source": [
    "Running this cell creates a [Run in Neptune](https://app.neptune.ai/o/common/org/showroom/e/SHOW-3700), and you can log model building metadata to it.\n",
    "\n",
    "**Click on the link above to open the Run in Neptune UI.** \n",
    "\n",
    "For now, it is empty, but you should keep the tab open to see what happens next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WbPjLDk1GcC"
   },
   "source": [
    "## Step 2: Log config and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVJKNQxIYPAC"
   },
   "source": [
    "### Log Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_8vefGCNBIJ"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"epochs\": 3,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"batch_size\": 10,\n",
    "    \"input_size\": 32 * 32 * 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"k_folds\": 5,\n",
    "    \"model_name\": \"checkpoint.pth\",\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0Ig4exNSMwE"
   },
   "outputs": [],
   "source": [
    "run[\"global/params\"] = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2rAXguq0_IZ"
   },
   "source": [
    "### Log Config\n",
    "Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwdf0rrklZWi"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i19Y0g3YGvV2"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(parameters[\"seed\"])\n",
    "model = BaseModel(\n",
    "    parameters[\"input_size\"], parameters[\"input_size\"], parameters[\"n_classes\"]\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=parameters[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viTM9XYl4-C0"
   },
   "source": [
    "Log model, criterion and optimizer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iZSQE5DYyqX"
   },
   "outputs": [],
   "source": [
    "run[\"global/config/model\"] = type(model).__name__\n",
    "run[\"global/config/criterion\"] = type(criterion).__name__\n",
    "run[\"global/config/optimizer\"] = type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2gKRp-8THxa"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_dir = \"data/CIFAR10\"\n",
    "compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMa-mrc64qjz",
    "outputId": "33361efd-c719-4221-8b1e-d7298e1d3904"
   },
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "\n",
    "validset = datasets.CIFAR10(\n",
    "    data_dir, train=False, transform=data_tfms[\"train\"], download=True\n",
    ")\n",
    "\n",
    "dataset_size = len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mXZEVnl4-C1"
   },
   "source": [
    "Log dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKFjiUDqgTqT"
   },
   "outputs": [],
   "source": [
    "run[\"global/dataset/CIFAR-10\"].track_files(data_dir)\n",
    "run[\"global/dataset/dataset_transforms\"] = data_tfms\n",
    "run[\"global/dataset/dataset_size\"] = dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRaqN0ug1KP_"
   },
   "source": [
    "## Step 3: Log losses and metrics per fold \n",
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "splits = KFold(n_splits=parameters[\"k_folds\"], shuffle=True)\n",
    "epoch_acc_list, epoch_loss_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgGfdruzNB3t"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "\n",
    "for fold, (train_ids, _) in enumerate(splits.split(trainset)):\n",
    "    train_sampler = SubsetRandomSampler(train_ids)\n",
    "    train_loader = DataLoader(\n",
    "        trainset, batch_size=parameters[\"batch_size\"], sampler=train_sampler\n",
    "    )\n",
    "    for epoch in range(parameters[\"epochs\"]):\n",
    "        epoch_acc, epoch_loss = 0, 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, y)\n",
    "            acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "            # Log batch loss and acc\n",
    "            run[f\"fold_{fold}/training/batch/loss\"].log(loss)\n",
    "            run[f\"fold_{fold}/training/batch/acc\"].log(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_acc += torch.sum(preds == y.data).item()\n",
    "        epoch_loss += loss.item() * x.size(0)\n",
    "\n",
    "    epoch_acc_list.append((epoch_acc / len(train_loader.sampler)) * 100)\n",
    "    epoch_loss_list.append(epoch_loss / len(train_loader.sampler))\n",
    "\n",
    "    # Log model checkpoint\n",
    "    torch.save(model.state_dict(), f\"./{parameters['model_name']}\")\n",
    "    run[f\"fold_{fold}/checkpoint\"].upload(parameters[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pC_GC8bXVW2"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# log global acc and loss\n",
    "run[\"global/metrics/train/mean_acc\"] = mean(epoch_acc_list)\n",
    "run[\"global/metrics/train/mean_loss\"] = mean(epoch_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhE6C9xv-lXK"
   },
   "source": [
    "## Stop run\n",
    "\n",
    "**Warning**\n",
    "\n",
    "Once you are done logging, you should stop tracking the run using the `stop()` method.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Meg02T9p9314",
    "outputId": "d2314d4f-e7ca-40ed-a3ff-b89d2047bf68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the run in the Neptune UI\n",
    "\n",
    "After running the code cell in **Step 1**, you will get a link on the cell output similar to https://app.neptune.ai/common/showroom/e/SHOW-3700 with: \n",
    "* **common/showroom** replaced by **your_workspace/your_project**,\n",
    "* **SHOW-3700** replaced by your *Run ID*. \n",
    "\n",
    "**Click on the link to open the Run in Neptune UI.**\n",
    "\n",
    "![image](https://files.gitbook.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MT0sYKbymfLAAtTq4-t%2Fuploads%2FnP5NQ7TUcuqr47cCERGk%2Fper_fold_metadata.gif?alt=media&token=1f851480-3881-4320-8b67-fb0bcc3e0bce)\n",
    "<center><small>Analysing per-fold metadata</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with Integrations\n",
    "If you are using Neptune with XGBoost or LightGBM you can get the structure for cross-validation automatically, by using available integrations.\n",
    "<div style=\"position: relative; padding-bottom: 62.5%; height: 0;\"><iframe src=\"https://www.loom.com/embed/98dc6247c65f49b8baf7476cf996dbe4\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\"></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You learned how to organize your run to track cross-validation metadata with Neptune and how to present the result in the Neptune UI for further comparison and analysis. \n",
    "\n",
    "Visit our docs for more tutorials and guides on how to use Neptune: https://docs.neptune.ai\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_cross_validation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "af60d0baf4ea5b6ff70d540328aa92d791e2ab8d07968cfca7a92cb88135beaf"
  },
  "kernelspec": {
   "display_name": "Python (neptune)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
