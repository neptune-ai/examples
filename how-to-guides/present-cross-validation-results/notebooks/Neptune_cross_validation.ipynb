{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to present CV with Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When training models with cross-validation, you can use Neptune namespaces to organize, visualize and compare models.\n",
    "\n",
    "By the end of this guide, you will learn how to organize your run to track cross-validation metadata, so that you can easily analyze the results.\n",
    "\n",
    "[See this example in Neptune](https://app.neptune.ai/o/common/org/showroom/e/SHOW-27624)\n",
    "\n",
    "<center>\n",
    "    <a href=\"https://app.neptune.ai/o/common/org/showroom/e/SHOW-27624\">\n",
    "        <img src=\"https://neptune.ai/wp-content/uploads/metadata-in-neptune.png\" alt=\"Drawing\" style=\"height: 600px;\">\n",
    "    </a>\n",
    "</center>\n",
    "<center><small>CV results presented in Neptune UI</small></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune as an anonymous user, with zero setup.\n",
    "\n",
    "* If you are running the notebook on your local machine, you need to have [Python](https://www.python.org/downloads/) and [pip](https://pypi.org/project/pip/) installed.\n",
    "* If you want to see the example recorded to your own workspace instead:\n",
    "    * Create a Neptune account → [Take me to registration](https://neptune.ai/register)\n",
    "    * Create a Neptune project that you will use for tracking metadata → [Tell me more about projects](https://docs.neptune.ai/administration/projects) \n",
    "<br><br>\n",
    "* This example assumes: \n",
    "    * Basic familiarity with Neptune ([create run and log metadata to it](https://docs.neptune.ai/you-should-know/what-can-you-log-and-display)),\n",
    "    * Familiarity with cross-validation techniques in machine learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -U neptune-client scikit-learn torch torchvision tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a run\n",
    "\n",
    "To connect your script to Neptune and create a new run, we tell Neptune:\n",
    "* **Who you are** - with a Neptune API token\n",
    "* **Where to send your data** - to a Neptune project\n",
    "\n",
    "The cell below lets you record data to the public project [common/quickstarts](https://app.neptune.ai/common/quickstarts) as an anonymous user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect your script to Neptune application and create new run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"common/showroom\",\n",
    "    api_token=neptune.ANONYMOUS_API_TOKEN,\n",
    "    tags=[\"cross-validation\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can log the example to your own workspace.\n",
    "\n",
    "To do that, replace the code above with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "run = neptune.init_run(\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    project=\"workspace-name/project-name\",  # replace with your own\n",
    ")\n",
    "```\n",
    "\n",
    "For example, if your workspace name is `ml-team` and the project name is `classification`, the project argument is: `project=\"ml-team/classification\"`.\n",
    "\n",
    "To find your API token and project name, [log in to Neptune](https://app.neptune.ai/).\n",
    "- In the top-right corner, click your avatar and select **Get your API token**.\n",
    "- To find and copy your project name, navigate to the project, then click **Settings** → **Properties**.\n",
    "\n",
    "---\n",
    "\n",
    "You now have new run in Neptune! From here on, we'll use the `run` object to log metadata.\n",
    "\n",
    "**To open the run in Neptune, follow the link that appeared in the cell output.**\n",
    "\n",
    "There's not much to display yet, but keep the tab with the run open to see what happens next."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log config and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"epochs\": 2,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"batch_size\": 10,\n",
    "    \"image_size\": (3, 32, 32),\n",
    "    \"n_classes\": 10,\n",
    "    \"k_folds\": 2,\n",
    "    \"checkpoint_name\": \"checkpoint.pth\",\n",
    "    \"dataset_size\": 1000,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"parameters\"] = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Config\n",
    "Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, math.prod(parameters[\"image_size\"]))\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "run[\"parameters/device\"] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(parameters[\"seed\"])\n",
    "\n",
    "model = BaseModel(\n",
    "    math.prod(parameters[\"image_size\"]),\n",
    "    math.prod(parameters[\"image_size\"]),\n",
    "    parameters[\"n_classes\"],\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=parameters[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log model, criterion and optimizer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"parameters/model/name\"] = type(model).__name__\n",
    "run[\"parameters/model/criterion\"] = type(criterion).__name__\n",
    "run[\"parameters/model/optimizer\"] = type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.FakeData(\n",
    "    size=parameters[\"dataset_size\"],\n",
    "    image_size=parameters[\"image_size\"],\n",
    "    num_classes=parameters[\"n_classes\"],\n",
    "    transform=data_tfms[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"dataset/transforms\"] = data_tfms\n",
    "run[\"dataset/size\"] = parameters[\"dataset_size\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log losses and metrics per fold \n",
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "splits = KFold(n_splits=parameters[\"k_folds\"], shuffle=True)\n",
    "epoch_acc_list, epoch_loss_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "for fold, (train_ids, _) in tqdm(enumerate(splits.split(dataset))):\n",
    "    train_sampler = SubsetRandomSampler(train_ids)\n",
    "    train_loader = DataLoader(dataset, batch_size=parameters[\"batch_size\"], sampler=train_sampler)\n",
    "    for _ in trange(parameters[\"epochs\"]):\n",
    "        epoch_acc, epoch_loss = 0, 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, y)\n",
    "            acc = (torch.sum(preds == y.data)) / len(x)\n",
    "\n",
    "            # Log batch loss and acc\n",
    "            run[f\"fold_{fold}/training/batch/loss\"].log(loss)\n",
    "            run[f\"fold_{fold}/training/batch/acc\"].log(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_acc += torch.sum(preds == y.data).item()\n",
    "        epoch_loss += loss.item() * x.size(0)\n",
    "\n",
    "    epoch_acc_list.append((epoch_acc / len(train_loader.sampler)) * 100)\n",
    "    epoch_loss_list.append(epoch_loss / len(train_loader.sampler))\n",
    "\n",
    "    # Log model checkpoint\n",
    "    torch.save(model.state_dict(), f\"./{parameters['checkpoint_name']}\")\n",
    "    run[f\"fold_{fold}/checkpoint\"].upload(parameters[\"checkpoint_name\"])\n",
    "    run.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# log mean acc and loss\n",
    "run[\"results/metrics/train/mean_acc\"] = mean(epoch_acc_list)\n",
    "run[\"results/metrics/train/mean_loss\"] = mean(epoch_loss_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, stop tracking the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the run in Neptune\n",
    "\n",
    "After starting a run, you will get a link on the cell output similar to https://app.neptune.ai/o/common/org/showroom/e/SHOW-27624 with: \n",
    "* **common/showroom** replaced by **your_workspace/your_project**,\n",
    "* **SHOW-27624** replaced by your *run ID*. \n",
    "\n",
    "**Click on the link to open the run in Neptune app.**\n",
    "\n",
    "<img src=\"https://neptune.ai/wp-content/uploads/metadata-in-neptune-5.gif\" alt=\"Drawing\" style=\"width: 100%;\"/>\n",
    "<center><small>Analysing per-fold metadata</small></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with Integrations\n",
    "If you are using Neptune with XGBoost or LightGBM you can get the structure for cross-validation automatically, by using available [integrations](https://docs.neptune.ai/integrations/).\n",
    "<div style=\"position: relative; padding-bottom: 62.5%; height: 0;\"><iframe src=\"https://www.loom.com/embed/98dc6247c65f49b8baf7476cf996dbe4\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\"></iframe></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You learned how to organize your run to track cross-validation metadata with Neptune and how to present the result in the Neptune app for further comparison and analysis. \n",
    "\n",
    "Visit our docs for more tutorials and guides on how to use Neptune: https://docs.neptune.ai\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_cross_validation.ipynb",
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b6aa213b6465b4ab164cf3dabb5ccb1ebf5716f03f3b11b712c7a544a80e074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
